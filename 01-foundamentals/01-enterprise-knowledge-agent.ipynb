{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure AI Agent Service Enterprise Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Necessary Libraries\n",
    "In this cell, we import all the libraries and modules required for the project.\n",
    "This includes Azure AI SDKs, Gradio for UI, and custom functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment and authentication OK\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import uuid\n",
    "from datetime import datetime as pydatetime\n",
    "from typing import Any, List, Dict\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# (Optional) Gradio app for UI\n",
    "import gradio as gr\n",
    "from gradio import ChatMessage\n",
    "import base64\n",
    "\n",
    "# Azure AI Projects\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "from azure.ai.projects import AIProjectClient\n",
    "import azure.ai.agents as agentslib\n",
    "import azure.ai.projects as projectslib\n",
    "from azure.ai.agents.models import (\n",
    "    AgentEventHandler,\n",
    "    RunStep,\n",
    "    RunStepDeltaChunk,\n",
    "    ThreadMessage,\n",
    "    ThreadRun,\n",
    "    MessageDeltaChunk,\n",
    "    BingGroundingTool,\n",
    "    FilePurpose,\n",
    "    FileSearchTool,\n",
    "    FunctionTool,\n",
    "    ToolSet,\n",
    "    VectorStore,\n",
    "    AzureAISearchTool,\n",
    "    CodeInterpreterTool,\n",
    "    MessageDeltaTextContent,\n",
    "    MessageDeltaImageFileContent,\n",
    "    MessageDeltaTextContentObject,\n",
    "    MessageDeltaTextUrlCitationAnnotation,\n",
    "    MessageRole,\n",
    "    AgentThread,\n",
    "    MessageTextContent,\n",
    "    AgentsNamedToolChoice,\n",
    "    AgentsToolChoiceOptionMode,\n",
    "    AgentsNamedToolChoiceType,\n",
    ")\n",
    "\n",
    "# Your custom Python functions (for \"fetch_datetime\", etc.)\n",
    "from utils.enterprise_functions import enterprise_fns\n",
    "\n",
    "load_dotenv(dotenv_path=\".env\", override=True)\n",
    "\n",
    "from utils.fdyauth import AuthHelper\n",
    "settings = AuthHelper.load_settings()\n",
    "credential = AuthHelper.test_credential()\n",
    "\n",
    "if credential:\n",
    "    print('Environment and authentication OK')\n",
    "else:\n",
    "    print(\"please login first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Client and Load Azure AI Foundry\n",
    "Here, we initialize the Azure AI client using DefaultAzureCredential.\n",
    "This allows us to authenticate and connect to the Azure AI service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project_client api version: 2025-05-15-preview\n",
      "azure-ai-agents version: 1.1.0b3\n",
      "azure-ai-projects version: 1.0.0b12\n"
     ]
    }
   ],
   "source": [
    "# new AI Foundry Project resource endpoint / old azure ai services endpoint from the hub/project\n",
    "project_client = AIProjectClient(\n",
    "    credential=credential,\n",
    "    endpoint=settings.project_endpoint,\n",
    "    # api_version=os.environ[\"PROJECT_API_VERSION\"]\n",
    ")\n",
    "print(\"project_client api version:\", project_client._config.api_version)\n",
    "print(f\"azure-ai-agents version: {agentslib.__version__}\")\n",
    "print(f\"azure-ai-projects version: {projectslib.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Tools (BingGroundingTool, FileSearchTool)\n",
    "In this step, we configure tools such as `BingGroundingTool` and `FileSearchTool`.\n",
    "We check for existing connections and create or reuse vector stores for document search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "If you see the following cell has error:\n",
    "```\n",
    "AzureCliCredential: Please run 'az login' to set up an account\n",
    "```\n",
    "\n",
    "relogin from powershell\n",
    "```powershell\n",
    "az logout\n",
    "az account clear\n",
    "az login --tenant 00000000-0000-0000-0000-000000000000\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bing > connected\n",
      "reusing vector store > hr-policy-vector-store (id: vs_AMBfvCNoWCerPKW15891APxf)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    bing_connection = project_client.connections.get(name=os.environ[\"BING_CONNECTION_NAME\"])\n",
    "    # print(f\"{bing_connection}\")\n",
    "    conn_id = bing_connection.id\n",
    "    bing_tool = BingGroundingTool(connection_id=conn_id)\n",
    "    print(\"bing > connected\")\n",
    "except Exception:\n",
    "    bing_tool = None\n",
    "    print(\"bing failed > no connection found or permission issue\")\n",
    "\n",
    "## need to be wrapped inside the agents_client, close agents_client if done\n",
    "FOLDER_NAME = \"enterprise-data\"\n",
    "VECTOR_STORE_NAME = \"hr-policy-vector-store\"\n",
    "\n",
    "# project_client.agents return the AgentsClient\n",
    "all_vector_stores: List[VectorStore] = project_client.agents.vector_stores.list()\n",
    "\n",
    "existing_vector_store = next(\n",
    "    (store for store in all_vector_stores if store.name == VECTOR_STORE_NAME),\n",
    "    None\n",
    ")\n",
    "\n",
    "vector_store_id = None\n",
    "if existing_vector_store:\n",
    "    vector_store_id = existing_vector_store.id\n",
    "    print(f\"reusing vector store > {existing_vector_store.name} (id: {existing_vector_store.id})\")\n",
    "else:\n",
    "    # If you have local docs to upload\n",
    "    import os\n",
    "    if os.path.isdir(FOLDER_NAME):\n",
    "        file_ids = []\n",
    "        for file_name in os.listdir(FOLDER_NAME):\n",
    "            file_path = os.path.join(FOLDER_NAME, file_name)\n",
    "            if os.path.isfile(file_path):\n",
    "                print(f\"uploading > {file_name}\")\n",
    "                uploaded_file = project_client.agents.files.upload_and_poll(\n",
    "                    file_path=file_path,\n",
    "                    purpose=FilePurpose.AGENTS\n",
    "                )\n",
    "                file_ids.append(uploaded_file.id)\n",
    "\n",
    "        if file_ids:\n",
    "            print(f\"creating vector store > from {len(file_ids)} files.\")\n",
    "            vector_store = project_client.agents.vector_stores.create_and_poll(\n",
    "                file_ids=file_ids,\n",
    "                name=VECTOR_STORE_NAME\n",
    "            )\n",
    "            vector_store_id = vector_store.id\n",
    "            print(f\"created > {vector_store.name} (id: {vector_store_id})\")\n",
    "\n",
    "file_search_tool = None\n",
    "if vector_store_id:\n",
    "    file_search_tool = FileSearchTool(vector_store_ids=[vector_store_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azure ai search > connected directly to index\n"
     ]
    }
   ],
   "source": [
    "# Get the connection ID for your Azure AI Search resource\n",
    "try:\n",
    "    aisearch_connections = project_client.connections.list()\n",
    "    idx_conn_id = next(\n",
    "        c.id for c in aisearch_connections if c.name == os.environ.get(\"AZURE_SEARCH_CONNECTION_NAME\")\n",
    "    )\n",
    "\n",
    "    # Initialize Azure AI Search tool for direct index access\n",
    "    search_tool = AzureAISearchTool(\n",
    "        index_connection_id=idx_conn_id,\n",
    "        index_name=os.environ.get(\"AZURE_SEARCH_INDEX_NAME\")\n",
    "    )\n",
    "    print(\"azure ai search > connected directly to index\")\n",
    "except Exception as e:\n",
    "    search_tool = None\n",
    "    print(f\"azure ai search > skipped (no connection configured): {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine All Tools into a ToolSet\n",
    "This step creates a custom `ToolSet` that includes all the tools configured earlier.\n",
    "It also adds a `LoggingToolSet` subclass to log the inputs and outputs of function calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tool > BingGroundingTool\n",
      "tool > FunctionTool\n",
      "tool > AzureAISearchTool\n"
     ]
    }
   ],
   "source": [
    "class LoggingToolSet(ToolSet):\n",
    "    def execute_tool_calls(self, tool_calls: List[Any]) -> List[dict]:\n",
    "        \"\"\"\n",
    "        Execute the upstream calls, printing only two lines per function:\n",
    "        1) The function name + its input arguments\n",
    "        2) The function name + its output result\n",
    "        \"\"\"\n",
    "\n",
    "        # For each function call, print the input arguments\n",
    "        for c in tool_calls:\n",
    "            if hasattr(c, \"function\") and c.function:\n",
    "                fn_name = c.function.name\n",
    "                fn_args = c.function.arguments\n",
    "                print(f\"{fn_name} inputs > {fn_args} (id:{c.id})\")\n",
    "\n",
    "        # Execute the tool calls (superclass logic)\n",
    "        raw_outputs = super().execute_tool_calls(tool_calls)\n",
    "\n",
    "        # Print the output of each function call\n",
    "        for item in raw_outputs:\n",
    "            print(f\"output > {item['output']}\")\n",
    "\n",
    "        return raw_outputs\n",
    "\n",
    "# need an empty toolset to add tools\n",
    "custom_functions = FunctionTool(enterprise_fns)\n",
    "\n",
    "toolset = LoggingToolSet()\n",
    "\n",
    "# if file_search_tool:\n",
    "#      toolset.add(file_search_tool)\n",
    "if bing_tool:\n",
    "    toolset.add(bing_tool)\n",
    "toolset.add(custom_functions)\n",
    "if search_tool:\n",
    "    toolset.add(search_tool)\n",
    "\n",
    "for tool in toolset._tools:\n",
    "    tool_name = tool.__class__.__name__\n",
    "    print(f\"tool > {tool_name}\")\n",
    "    for definition in tool.definitions:\n",
    "        if hasattr(definition, \"function\"):\n",
    "            fn = definition.function\n",
    "            print(f\"{fn.name} > {fn.description}\")\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create or Reuse the Enterprise Agent\n",
    "In this step, we create a new enterprise agent or reuse an existing one.\n",
    "The agent is configured with a model, instructions, and the toolset from the previous step.\n",
    "\n",
    "Note:\n",
    "* You will need to delete the previous agent, while recreate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reusing agent > enterprise-knowledge-agent (id: asst_kg2qkcV8mMZbTwty4kX3CDgA)\n"
     ]
    }
   ],
   "source": [
    "AGENT_NAME = \"enterprise-knowledge-agent\"\n",
    "found_agent = None\n",
    "all_agents_list = project_client.agents.list_agents()\n",
    "for a in all_agents_list:\n",
    "    if a.name == AGENT_NAME:\n",
    "        found_agent = a\n",
    "        break\n",
    "\n",
    "model_name = settings.model_deployment_name\n",
    "\n",
    "# \"fetch_datetime\": \"ðŸ•’ fetching datetime\",\n",
    "# \"file_search\": \"ðŸ“„ searching docs\",\n",
    "# \"bing_grounding\": \"ðŸ” searching bing\",\n",
    "# \"azure_ai_search\": \"ðŸ”Ž ai search private index\",\n",
    "\n",
    "instructions = (\n",
    "    \"You are a helpful enterprise assistant at Contoso. \"\n",
    "    \"You have access to following tools. \\n\\n\"\n",
    "    \"## Tools:\\n\"\n",
    "    \" * azure_ai_search: get information about company financial reportings\\n\"\n",
    "    \" * file_search: get informaton about company Human Resource documents\\n\"\n",
    "    \" * bing_grounding: get information about latest news from the public web.\\n\"\n",
    "    \" * fetch_datetime: to get the current date/time.\\n\"\n",
    "    \"\\n\"\n",
    "    \"## Instructions:\\n\"\n",
    "    \"You can use the all the tools to answer questions\\n\"\n",
    "    \"\\n\"\n",
    "    \"## Guidelines:\\n\"\n",
    "    \"Provide well-structured and professional answers. \"\n",
    ")\n",
    "\n",
    "project_client.agents.enable_auto_function_calls(tools=toolset, max_retry=4)\n",
    "\n",
    "if found_agent:\n",
    "    # print(found_agent)\n",
    "    # Update the existing agent to use new tools\n",
    "    agent = project_client.agents.update_agent(\n",
    "        agent_id=found_agent.id,\n",
    "        model=model_name,\n",
    "        instructions=instructions,\n",
    "        toolset=toolset,\n",
    "    )\n",
    "    project_client.agents.enable_auto_function_calls(tools=toolset) \n",
    "    print(f\"reusing agent > {agent.name} (id: {agent.id})\")\n",
    "else:\n",
    "    agent = project_client.agents.create_agent(\n",
    "        model=model_name,\n",
    "        name=AGENT_NAME,\n",
    "        instructions=instructions,\n",
    "        toolset=toolset,\n",
    "    )\n",
    "    print(f\"creating agent > {agent.name} (id: {agent.id})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Conversation Thread\n",
    "In this step, we create a new conversation thread for the enterprise agent.\n",
    "Threads are used to manage and track conversations with the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread > created (id: thread_8vtJvUKu4ODlA50UUlF0v3bS)\n"
     ]
    }
   ],
   "source": [
    "thread = project_client.agents.threads.create()\n",
    "print(f\"thread > created (id: {thread.id})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Manipulate the thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Testing AI Search tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread > created (id: thread_TjJbCv2E1s62FkfWoKbOgXdu)\n",
      "message > created (id: msg_kagy3QIZFR4TnkLrZ5kYkZqh)\n"
     ]
    }
   ],
   "source": [
    "thread_whole_conversation = project_client.agents.threads.create()\n",
    "print(f\"thread > created (id: {thread_whole_conversation.id})\")\n",
    "\n",
    "user_prompt_1 = \"summarize siemens fiscal report 2024 from my company source\"\n",
    "\n",
    "def generate_conversation_thread_single(current_thread: AgentThread, user_prompt: str):\n",
    "    msg = project_client.agents.messages.create(\n",
    "        thread_id=current_thread.id,\n",
    "        role=MessageRole.USER,\n",
    "        content=user_prompt\n",
    "    )\n",
    "    print(f\"message > created (id: {msg.id})\")\n",
    "\n",
    "def display_message(thread_message: ThreadMessage):\n",
    "    for agent_message in thread_message.content:\n",
    "        if isinstance(agent_message, MessageTextContent):\n",
    "            agent_msg_obj = agent_message.text\n",
    "            annotations = agent_msg_obj.get(\"annotations\", None)\n",
    "            print(f\"agent message text > {agent_msg_obj.value} (id: {thread_message.id})\")\n",
    "            # get the grounding information from the agent message\n",
    "            if annotations and isinstance(annotations, list) and len(annotations) > 0:\n",
    "                print(f\"\\nGrounding > {annotations}\")\n",
    "\n",
    "# put the conversation history single agent to the thread\n",
    "generate_conversation_thread_single(current_thread=thread_whole_conversation, user_prompt=user_prompt_1)\n",
    "\n",
    "# run agent based on the thread conversation history\n",
    "# run = project_client.agents.runs.create_and_process(thread_id=thread_whole_conversation.id, agent_id=agent.id, temperature=0.1, tool_choice=AgentsToolChoiceOptionMode.AUTO)\n",
    "\n",
    "# enforce the agent to always use the tools\n",
    "run = project_client.agents.runs.create_and_process(thread_id=thread_whole_conversation.id, agent_id=agent.id, temperature=0.1, tool_choice=AgentsNamedToolChoice(type=AgentsNamedToolChoiceType.AZURE_AI_SEARCH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent message text > The Siemens Fiscal Report for 2024 highlights several key financial and operational achievements:\n",
      "\n",
      "1. Profit Margins and Segment Performance:\n",
      "   - Siemens Healthineers and Smart Infrastructure achieved strong profit margin increases to 14.2% and 17.3%, respectively.\n",
      "   - Mobility improved its profit margin to 8.9%.\n",
      "   - Digital Industries, while still contributing the highest profit margin among industrial businesses, saw a decline to 18.9%.\n",
      "\n",
      "2. Earnings and Returns:\n",
      "   - Siemens Financial Services (SFS) saw significant earnings before taxes growth, with a return on equity after tax rising to 17.6%.\n",
      "   - A gain of â‚¬0.5 billion was realized from the transfer of an 8.0% stake in Siemens Energy AG to Siemens Pension-Trust e.V.\n",
      "\n",
      "3. Net Income and Earnings Per Share (EPS):\n",
      "   - Net income reached a historic high of â‚¬9.0 billion.\n",
      "   - Basic EPS increased to â‚¬10.53, with EPS pre-PPA at â‚¬11.15.\n",
      "   - Excluding Siemens Energy Investment, EPS pre-PPA was â‚¬10.54, meeting the forecast range of â‚¬10.40 to â‚¬11.00.\n",
      "\n",
      "4. Return on Capital Employed (ROCE) and Capital Structure:\n",
      "   - ROCE rose to 19.1%, within the target range of 15% to 20%.\n",
      "   - The ratio of Industrial net debt to EBITDA was 0.7, well below the forecasted maximum of 1.5.\n",
      "\n",
      "5. Cash Flow:\n",
      "   - Free cash flow from continuing and discontinued operations was â‚¬9.5 billion, slightly below the record â‚¬10.0 billion in 2023.\n",
      "   - The cash conversion rate remained strong.\n",
      "\n",
      "6. Revenue Growth and Orders:\n",
      "   - The book-to-bill ratio was 1.11, indicating healthy order intake relative to revenue.\n",
      "   - Currency translation effects had a negative impact of two percentage points on both orders and revenue growth.\n",
      "\n",
      "7. Reporting Changes:\n",
      "   - Siemens ceased reporting financial results for Portfolio Companies in 2024.\n",
      "   - Some reclassifications and transfers of items such as Siemens Energy Investment and Siemens Real Estate to different reporting categories will take effect starting fiscal 2025.\n",
      "\n",
      "Overall, Siemens demonstrated strong financial performance in fiscal 2024 with record net income, solid profit margins in key segments, efficient capital use, and robust cash flow, while also preparing for some structural changes in reporting for the next fiscal year.\n",
      "\n",
      "If you need more detailed information on specific segments or financial metrics, please let me know. \n",
      "\n",
      "This summary is based on the Siemens Fiscal Report 2024 from your company source documentsã€3:1â€ sourceã€‘ã€3:2â€ sourceã€‘ã€3:3â€ sourceã€‘ã€3:4â€ sourceã€‘. (id: msg_6LZ6mrnuNE8hQdvmYYgEXGni)\n",
      "\n",
      "Grounding > [{'type': 'url_citation', 'text': 'ã€3:1â€ sourceã€‘', 'start_index': 2419, 'end_index': 2431, 'url_citation': {'url': 'doc_1', 'title': 'Siemens_Report_FY2024.pdf'}}, {'type': 'url_citation', 'text': 'ã€3:2â€ sourceã€‘', 'start_index': 2431, 'end_index': 2443, 'url_citation': {'url': 'doc_2', 'title': 'Siemens_Report_FY2024.pdf'}}, {'type': 'url_citation', 'text': 'ã€3:3â€ sourceã€‘', 'start_index': 2443, 'end_index': 2455, 'url_citation': {'url': 'doc_3', 'title': 'Siemens_Report_FY2024.pdf'}}, {'type': 'url_citation', 'text': 'ã€3:4â€ sourceã€‘', 'start_index': 2455, 'end_index': 2467, 'url_citation': {'url': 'doc_4', 'title': 'Siemens_Report_FY2024.pdf'}}]\n"
     ]
    }
   ],
   "source": [
    "agent_message_annotation: ThreadMessage = project_client.agents.messages.get_last_message_by_role(thread_id = thread_whole_conversation.id, role=MessageRole.AGENT)\n",
    "\n",
    "display_message(agent_message_annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Bing grounding tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread > created (id: thread_rpkgmPzHIob4QtLV22nBRjVi)\n",
      "message > created (id: msg_IM1Lw8WjP4TE1218eWGZI6Tu)\n"
     ]
    }
   ],
   "source": [
    "user_prompt_2 = \"tell me about the latest news about microsoft azure\"\n",
    "\n",
    "bing_grounding_thread = project_client.agents.threads.create()\n",
    "print(f\"thread > created (id: {bing_grounding_thread.id})\")\n",
    "\n",
    "# put the conversation history single agent to the thread\n",
    "generate_conversation_thread_single(current_thread=bing_grounding_thread, user_prompt=user_prompt_2)\n",
    "\n",
    "# run agent based on the thread conversation history\n",
    "run = project_client.agents.runs.create_and_process(thread_id=bing_grounding_thread.id, agent_id=agent.id, temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent message text > The latest news about Microsoft Azure highlights several key updates and innovations:\n",
      "\n",
      "1. Microsoft has been recognized as a leader in The Forrester Waveâ„¢: Serverless Development Platforms, Q2 2025, showcasing its strength in serverless compute on Azure.\n",
      "\n",
      "2. An IDC Business Value Study reported a 306% ROI within 3 years for organizations using Ubuntu Linux on Azure, emphasizing Azure's efficiency and effectiveness for Ubuntu workloads.\n",
      "\n",
      "3. Microsoft was named a Leader in the 2025 GartnerÂ® Magic Quadrantâ„¢ for Data Science and Machine Learning Platforms, as well as for Integration Platform as a Service, reflecting its strong position in AI-powered automation and data science.\n",
      "\n",
      "4. At Microsoft Build 2025, Microsoft announced 10 innovations in Azure AI Foundry to enhance AI agent capabilities for software development, along with new AI tools to empower developers.\n",
      "\n",
      "5. New strategic updates and innovations were announced for SAP on Microsoft Cloud at SAP Sapphire 2025.\n",
      "\n",
      "6. Microsoft is advancing Agentic DevOps with GitHub Copilot and Azure, aiming to evolve software development with AI agents that accelerate delivery while maintaining control.\n",
      "\n",
      "7. The Azure ecosystem continues to expand with new features in Microsoft Fabric, Azure Container Apps, and enhanced security and data protection capabilities.\n",
      "\n",
      "These updates reflect Microsoft's ongoing commitment to innovation, AI integration, and cloud platform leadership with Azure. For more detailed information, you can visit the official Microsoft Azure updates page and blog. \n",
      "\n",
      "If you want, I can provide specific details on any of these topics. (id: msg_s96aXxMncDR4lNtijgTsuk5C)\n"
     ]
    }
   ],
   "source": [
    "bing_grounding_agent_thread_message: ThreadMessage = project_client.agents.messages.get_last_message_by_role(thread_id = bing_grounding_thread.id, role=MessageRole.AGENT)\n",
    "\n",
    "display_message(bing_grounding_agent_thread_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Content Filter with Block List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread > created (id: thread_bMVg4KZub3UJb1a7S1G51fJN)\n",
      "message > created (id: msg_KkWQz8lSWf8ImYfr5OjZHMXq)\n"
     ]
    }
   ],
   "source": [
    "block_list_thread = project_client.agents.threads.create()\n",
    "print(f\"thread > created (id: {block_list_thread.id})\")\n",
    "\n",
    "# put the conversation history single agent to the thread\n",
    "user_prompt_3 = \"what is the latest news about google gcp?\"\n",
    "generate_conversation_thread_single(current_thread=block_list_thread, user_prompt=user_prompt_3)\n",
    "\n",
    "# run agent based on the thread conversation history\n",
    "run = project_client.agents.runs.create_and_process(thread_id=block_list_thread.id, agent_id=agent.id, temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent message text > I'm sorry, but I cannot assist with that request. (id: msg_q4HbF4Cs3NjjZQpNaU6pfnU2)\n"
     ]
    }
   ],
   "source": [
    "block_list_agent_thread_message: ThreadMessage = project_client.agents.messages.get_last_message_by_role(thread_id = block_list_thread.id, role=MessageRole.AGENT)\n",
    "\n",
    "display_message(block_list_agent_thread_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a Custom Event Handler\n",
    "Here, we define a custom event handler to manage logs and outputs for debugging.\n",
    "This handler will capture and display real-time events during the agent's operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyEventHandler(AgentEventHandler):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._current_message_id = None\n",
    "        self._accumulated_text = \"\"\n",
    "\n",
    "    def on_message_delta(self, delta: MessageDeltaChunk) -> None:\n",
    "        # If a new message id, start fresh\n",
    "        if delta.id != self._current_message_id:\n",
    "            # First, if we had an old message that wasn't completed, finish that line\n",
    "            if self._current_message_id is not None:\n",
    "                print()  # move to a new line\n",
    "            \n",
    "            self._current_message_id = delta.id\n",
    "            self._accumulated_text = \"\"\n",
    "            print(\"\\nassistant > \", end=\"\")  # prefix for new message\n",
    "\n",
    "        # Accumulate partial text\n",
    "        partial_text = \"\"\n",
    "        if delta.delta.content:\n",
    "            for chunk in delta.delta.content:\n",
    "                # partial_text += chunk.text.get(\"value\", \"\")\n",
    "                if isinstance(chunk, MessageDeltaTextContent):\n",
    "                    partial_text += chunk[\"text\"].get(\"value\", \"\")\n",
    "                elif isinstance(chunk, MessageDeltaImageFileContent):\n",
    "                    partial_text += chunk[\"image_file\"].get(\"file_id\", \"\")\n",
    "        self._accumulated_text += partial_text\n",
    "\n",
    "        # Print partial text with no newline\n",
    "        print(partial_text, end=\"\", flush=True)\n",
    "\n",
    "    def on_thread_message(self, message: ThreadMessage) -> None:\n",
    "        # When the assistant's entire message is \"completed\", print a final newline\n",
    "        if message.status == \"completed\" and message.role == \"assistant\":\n",
    "            print()  # done with this line\n",
    "            self._current_message_id = None\n",
    "            self._accumulated_text = \"\"\n",
    "        else:\n",
    "            # For other roles or statuses, you can log if you like:\n",
    "            print(f\"{message.status.name.lower()} (id: {message.id})\")\n",
    "\n",
    "    def on_thread_run(self, run: ThreadRun) -> None:\n",
    "        print(f\"status > {run.status.name.lower()}\")\n",
    "        if run.status == \"failed\":\n",
    "            print(f\"error > {run.last_error}\")\n",
    "\n",
    "    def on_run_step(self, step: RunStep) -> None:\n",
    "        print(f\"{step.type.name.lower()} > {step.status.name.lower()}\")\n",
    "\n",
    "    def on_run_step_delta(self, delta: RunStepDeltaChunk) -> None:\n",
    "        # If partial tool calls come in, we log them\n",
    "        if delta.delta.step_details and delta.delta.step_details.tool_calls:\n",
    "            for tcall in delta.delta.step_details.tool_calls:\n",
    "                if getattr(tcall, \"function\", None):\n",
    "                    if tcall.function.name is not None:\n",
    "                        print(f\"tool call > {tcall.function.name}\")\n",
    "\n",
    "    def on_unhandled_event(self, event_type: str, event_data):\n",
    "        print(f\"unhandled > {event_type} > {event_data}\")\n",
    "\n",
    "    def on_error(self, data: str) -> None:\n",
    "        print(f\"error > {data}\")\n",
    "\n",
    "    def on_done(self) -> None:\n",
    "        print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement the Main Chat Functions\n",
    "These functions define how user messages and tool interactions are processed.\n",
    "It uses the agent's thread to handle conversations and streams partial responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_bing_query(request_url: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract the query string from something like:\n",
    "      https://api.bing.microsoft.com/v7.0/search?q=\"latest news about Microsoft January 2025\"\n",
    "    Returns: latest news about Microsoft January 2025\n",
    "    \"\"\"\n",
    "    match = re.search(r'q=\"([^\"]+)\"', request_url)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    # If no match, fall back to entire request_url\n",
    "    return request_url\n",
    "\n",
    "def extract_search_annotation(\n",
    "        annotation: MessageDeltaTextUrlCitationAnnotation, text_value_str: str) -> str:\n",
    "    \"\"\"\n",
    "    {'index': 0, 'type': 'text', 'text': {'value': 'ã€3:1â€ Siemens fiscal report 2024ã€‘', 'annotations': [{'index': 0, 'type': 'url_citation', 'text': 'ã€3:1â€ Siemens fiscal report 2024ã€‘', 'start_index': 1369, 'end_index': 1401, 'url_citation': {'url': 'doc_1', 'title': 'Siemens_Report_FY2024.pdf'}}]}}\n",
    "\n",
    "    {'index': 0, 'type': 'text', 'text': {'value': 'ã€14:0â€ best_practices_lung_cancer.mdã€‘', 'annotations': [{'index': 0, 'type': 'file_citation', 'text': 'ã€14:0â€ best_practices_lung_cancer.mdã€‘', 'start_index': 2486, 'end_index': 2522, 'file_citation': {'file_id': 'assistant-XfXFvez3N2CbpttpNb8MK4', 'quote': ''}}]}}\n",
    "    \"\"\"\n",
    "    if annotation[\"type\"] == \"url_citation\":\n",
    "        url = annotation[\"url_citation\"][\"url\"]\n",
    "        title = annotation[\"url_citation\"].get(\"title\", \"\")\n",
    "        start_idx = annotation.get(\"start_index\", 0)\n",
    "        end_idx = annotation.get(\"end_index\", 0)\n",
    "        return f\" [{text_value_str.strip()} {title}]({url}) ({start_idx}-{end_idx})\"\n",
    "    elif annotation[\"type\"] == \"file_citation\":\n",
    "        # file_id = annotation[\"file_citation\"][\"file_id\"]\n",
    "        file_id = \"\"\n",
    "        quote = annotation[\"file_citation\"].get(\"quote\", \"\")\n",
    "        title = annotation[\"text\"]\n",
    "        start_idx = annotation.get(\"start_index\", 0)\n",
    "        end_idx = annotation.get(\"end_index\", 0)\n",
    "        return f\" [{text_value_str.strip()} {title}]({file_id}) ({start_idx}-{end_idx})\"\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "def convert_dict_to_chatmessage(msg: dict) -> ChatMessage:\n",
    "    \"\"\"\n",
    "    Convert a legacy dict-based message to a gr.ChatMessage.\n",
    "    Uses the 'metadata' sub-dict if present.\n",
    "    \"\"\"\n",
    "    return ChatMessage(\n",
    "        role=msg[\"role\"],\n",
    "        content=msg[\"content\"],\n",
    "        metadata=msg.get(\"metadata\", None)\n",
    "    )\n",
    "\n",
    "def azure_enterprise_chat(user_message: str, history: List[dict]):\n",
    "    \"\"\"\n",
    "    Accumulates partial function arguments into ChatMessage['content'], sets the\n",
    "    corresponding tool bubble status from \"pending\" to \"done\" on completion,\n",
    "    and also handles non-function calls like bing_grounding or file_search by appending a\n",
    "    \"pending\" bubble. Then it moves them to \"done\" once tool calls complete.\n",
    "\n",
    "    This function returns a list of ChatMessage objects directly (no dict conversion).\n",
    "    Your Gradio Chatbot should be type=\"messages\" to handle them properly.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert existing history from dict to ChatMessage\n",
    "    conversation = []\n",
    "    for msg_dict in history:\n",
    "        conversation.append(convert_dict_to_chatmessage(msg_dict))\n",
    "\n",
    "    # Append the user's new message\n",
    "    conversation.append(ChatMessage(role=\"user\", content=user_message))\n",
    "\n",
    "    # Immediately yield two outputs to clear the textbox\n",
    "    yield conversation, \"\"\n",
    "\n",
    "    # Post user message to the thread (for your back-end logic)\n",
    "    project_client.agents.messages.create(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=user_message\n",
    "    )\n",
    "\n",
    "    # Mappings for partial function calls\n",
    "    call_id_for_index: Dict[int, str] = {}\n",
    "    partial_calls_by_index: Dict[int, dict] = {}\n",
    "    partial_calls_by_id: Dict[str, dict] = {}\n",
    "    in_progress_tools: Dict[str, ChatMessage] = {}\n",
    "\n",
    "    # Titles for tool bubbles\n",
    "    function_titles = {\n",
    "        # \"fetch_weather\": \"â˜ï¸ fetching weather\",\n",
    "        \"fetch_datetime\": \"ðŸ•’ fetching datetime\",\n",
    "        # \"fetch_stock_price\": \"ðŸ“ˆ fetching financial info\",\n",
    "        # \"send_email\": \"âœ‰ï¸ sending mail\",\n",
    "        \"file_search\": \"ðŸ“„ searching docs\",\n",
    "        \"bing_grounding\": \"ðŸ” searching bing\",\n",
    "        \"azure_ai_search\": \"ðŸ”Ž ai search private index\",\n",
    "    }\n",
    "\n",
    "    def get_function_title(fn_name: str) -> str:\n",
    "        return function_titles.get(fn_name, f\"ðŸ›  calling {fn_name}\")\n",
    "\n",
    "    def accumulate_args(storage: dict, name_chunk: str, arg_chunk: str):\n",
    "        \"\"\"Accumulates partial JSON data for a function call.\"\"\"\n",
    "        if name_chunk:\n",
    "            storage[\"name\"] += name_chunk\n",
    "        if arg_chunk:\n",
    "            storage[\"args\"] += arg_chunk\n",
    "\n",
    "    def finalize_tool_call(call_id: str):\n",
    "        \"\"\"Creates or updates the ChatMessage bubble for a function call.\"\"\"\n",
    "        if call_id not in partial_calls_by_id:\n",
    "            return\n",
    "        data = partial_calls_by_id[call_id]\n",
    "        fn_name = data[\"name\"].strip()\n",
    "        fn_args = data[\"args\"].strip()\n",
    "        if not fn_name:\n",
    "            return\n",
    "\n",
    "        if call_id not in in_progress_tools:\n",
    "            # Create a new bubble with status=\"pending\"\n",
    "            msg_obj = ChatMessage(\n",
    "                role=\"assistant\",\n",
    "                content=fn_args or \"\",\n",
    "                metadata={\n",
    "                    \"title\": get_function_title(fn_name),\n",
    "                    \"status\": \"pending\",\n",
    "                    \"id\": f\"tool-{call_id}\"\n",
    "                }\n",
    "            )\n",
    "            conversation.append(msg_obj)\n",
    "            in_progress_tools[call_id] = msg_obj\n",
    "        else:\n",
    "            # Update existing bubble\n",
    "            msg_obj = in_progress_tools[call_id]\n",
    "            msg_obj.content = fn_args or \"\"\n",
    "            msg_obj.metadata[\"title\"] = get_function_title(fn_name)\n",
    "\n",
    "    def upsert_tool_call(tcall: dict):\n",
    "        \"\"\"\n",
    "        1) Check the call type\n",
    "        2) If \"function\", gather partial name/args\n",
    "        3) If \"bing_grounding\" or \"file_search\", show a pending bubble\n",
    "        \"\"\"\n",
    "        t_type = tcall.get(\"type\", \"\")\n",
    "        call_id = tcall.get(\"id\", None)\n",
    "\n",
    "        # If call_id is None, generate a unique one (for parallel calls)\n",
    "        # if call_id is None:\n",
    "        #     call_id = str(uuid.uuid4())\n",
    "        \n",
    "        # If call_id is None, generate a unique one (for parallel calls)\n",
    "        if call_id is None:\n",
    "            if t_type in (\"file_search\", \"bing_grounding\"):\n",
    "                call_id = str(uuid.uuid4())\n",
    "            elif t_type == \"code_interpreter\":\n",
    "                call_id = \"code_interpreter\"\n",
    "            elif t_type == \"azure_ai_search\":\n",
    "                call_id = \"azure_ai_search\"\n",
    "            else:\n",
    "                call_id = \"unknown_tool\"\n",
    "\n",
    "        # --- BING GROUNDING ---\n",
    "        if t_type == \"bing_grounding\":\n",
    "            request_url = tcall.get(\"bing_grounding\", {}).get(\"requesturl\", \"\")\n",
    "            if not request_url.strip():\n",
    "                return\n",
    "\n",
    "            query_str = extract_bing_query(request_url)\n",
    "            if not query_str.strip():\n",
    "                return\n",
    "\n",
    "            msg_obj = ChatMessage(\n",
    "                role=\"assistant\",\n",
    "                content=query_str,\n",
    "                metadata={\n",
    "                    \"title\": get_function_title(\"bing_grounding\"),\n",
    "                    \"status\": \"pending\",\n",
    "                    \"id\": f\"tool-{call_id}\" if call_id else \"tool-noid\"\n",
    "                }\n",
    "            )\n",
    "            conversation.append(msg_obj)\n",
    "            if call_id is not None:\n",
    "                in_progress_tools[call_id] = msg_obj\n",
    "            return\n",
    "\n",
    "        # --- FILE SEARCH ---\n",
    "        elif t_type == \"file_search\":\n",
    "            msg_obj = ChatMessage(\n",
    "                role=\"assistant\",\n",
    "                content=\"searching docs...\",\n",
    "                metadata={\n",
    "                    \"title\": get_function_title(\"file_search\"),\n",
    "                    \"status\": \"pending\",\n",
    "                    \"id\": f\"tool-{call_id}\" if call_id else \"tool-noid\"\n",
    "                }\n",
    "            )\n",
    "            conversation.append(msg_obj)\n",
    "            if call_id is not None:\n",
    "                in_progress_tools[call_id] = msg_obj\n",
    "            return\n",
    "        \n",
    "\n",
    "        # --- Azure AI SEARCH --- \n",
    "        elif t_type == \"azure_ai_search\":\n",
    "            if call_id not in in_progress_tools:\n",
    "                msg_obj = ChatMessage(\n",
    "                    role=\"assistant\",\n",
    "                    content=\"searching private index...\",\n",
    "                    metadata={\n",
    "                        \"title\": get_function_title(\"azure_ai_search\"),\n",
    "                        \"status\": \"pending\",\n",
    "                        \"id\": f\"tool-{call_id}\" if call_id else \"tool-noid\"\n",
    "                    }\n",
    "                )\n",
    "                conversation.append(msg_obj)\n",
    "                in_progress_tools[call_id] = msg_obj\n",
    "            return\n",
    "        \n",
    "        # -- CODE INTERPRETER ---\n",
    "        elif t_type == \"code_interpreter\":\n",
    "            if call_id not in in_progress_tools:\n",
    "                msg_obj = ChatMessage(\n",
    "                    role=\"assistant\",\n",
    "                    content=\"analyzing data...\",\n",
    "                    metadata={\n",
    "                        \"title\": get_function_title(\"code_interpreter\"),\n",
    "                        \"status\": \"pending\",\n",
    "                        \"id\": f\"tool-{call_id}\"\n",
    "                    }\n",
    "                )\n",
    "                conversation.append(msg_obj)\n",
    "                in_progress_tools[call_id] = msg_obj\n",
    "            return\n",
    "\n",
    "        # --- NON-FUNCTION CALLS ---\n",
    "        elif t_type != \"function\":\n",
    "            return\n",
    "\n",
    "        # --- FUNCTION CALL PARTIAL-ARGS ---\n",
    "        index = tcall.get(\"index\")\n",
    "        new_call_id = call_id\n",
    "        fn_data = tcall.get(\"function\", {})\n",
    "        name_chunk = fn_data.get(\"name\", \"\")\n",
    "        arg_chunk = fn_data.get(\"arguments\", \"\")\n",
    "\n",
    "        if new_call_id:\n",
    "            call_id_for_index[index] = new_call_id\n",
    "\n",
    "        call_id = call_id_for_index.get(index)\n",
    "        if not call_id:\n",
    "            # Accumulate partial\n",
    "            if index not in partial_calls_by_index:\n",
    "                partial_calls_by_index[index] = {\"name\": \"\", \"args\": \"\"}\n",
    "            accumulate_args(partial_calls_by_index[index], name_chunk, arg_chunk)\n",
    "            return\n",
    "\n",
    "        if call_id not in partial_calls_by_id:\n",
    "            partial_calls_by_id[call_id] = {\"name\": \"\", \"args\": \"\"}\n",
    "\n",
    "        if index in partial_calls_by_index:\n",
    "            old_data = partial_calls_by_index.pop(index)\n",
    "            partial_calls_by_id[call_id][\"name\"] += old_data.get(\"name\", \"\")\n",
    "            partial_calls_by_id[call_id][\"args\"] += old_data.get(\"args\", \"\")\n",
    "\n",
    "        # Accumulate partial\n",
    "        accumulate_args(partial_calls_by_id[call_id], name_chunk, arg_chunk)\n",
    "\n",
    "        # Create/update the function bubble\n",
    "        finalize_tool_call(call_id)\n",
    "\n",
    "    # -- EVENT STREAMING --\n",
    "    with project_client.agents.runs.stream(\n",
    "        thread_id=thread.id,\n",
    "        agent_id=agent.id,\n",
    "        # assistant_id=agent.id,\n",
    "        event_handler=MyEventHandler()  # the event handler handles console output\n",
    "    ) as stream:\n",
    "        # pulling the result from the stream manually\n",
    "        for item in stream:\n",
    "            event_type, event_data, *_ = item\n",
    "\n",
    "            # Remove any None items that might have been appended\n",
    "            conversation = [m for m in conversation if m is not None]\n",
    "\n",
    "            # 1) Partial tool calls\n",
    "            if event_type == \"thread.run.step.delta\":\n",
    "                step_delta = event_data.get(\"delta\", {}).get(\"step_details\", {})\n",
    "                if step_delta.get(\"type\") == \"tool_calls\":\n",
    "                    for tcall in step_delta.get(\"tool_calls\", []):\n",
    "                        upsert_tool_call(tcall)\n",
    "                    yield conversation, \"\"\n",
    "\n",
    "            # 2) run_step\n",
    "            elif event_type == \"run_step\":\n",
    "                step_type = event_data[\"type\"]\n",
    "                step_status = event_data[\"status\"]\n",
    "\n",
    "                # If tool calls are in progress, new or partial\n",
    "                if step_type == \"tool_calls\" and step_status == \"in_progress\":\n",
    "                    for tcall in event_data[\"step_details\"].get(\"tool_calls\", []):\n",
    "                        upsert_tool_call(tcall)\n",
    "                    yield conversation, \"\"\n",
    "\n",
    "                elif step_type == \"tool_calls\" and step_status == \"completed\":\n",
    "                    for cid, msg_obj in in_progress_tools.items():\n",
    "                        msg_obj.metadata[\"status\"] = \"done\"\n",
    "                    in_progress_tools.clear()\n",
    "                    partial_calls_by_id.clear()\n",
    "                    partial_calls_by_index.clear()\n",
    "                    call_id_for_index.clear()\n",
    "                    yield conversation, \"\"\n",
    "\n",
    "                elif step_type == \"message_creation\" and step_status == \"in_progress\":\n",
    "                    msg_id = event_data[\"step_details\"][\"message_creation\"].get(\"message_id\")\n",
    "                    if msg_id:\n",
    "                        conversation.append(ChatMessage(role=\"assistant\", content=\"\"))\n",
    "                    yield conversation, \"\"\n",
    "\n",
    "                elif step_type == \"message_creation\" and step_status == \"completed\":\n",
    "                    yield conversation, \"\"\n",
    "\n",
    "            # 3) partial text from the assistant\n",
    "            elif event_type == \"thread.message.delta\":\n",
    "                agent_msg = \"\"\n",
    "                for chunk in event_data[\"delta\"][\"content\"]:\n",
    "                    # print(\"chunk > \", chunk)\n",
    "                    if isinstance(chunk, MessageDeltaTextContent):\n",
    "                        # Safely get the text value\n",
    "                        text_obj: MessageDeltaTextContentObject = chunk.get(\"text\", {})\n",
    "                        text_value_str = text_obj.get(\"value\", \"\")\n",
    "                        annotations = text_obj.get(\"annotations\", None)\n",
    "                        if annotations:\n",
    "                            # Extract the URL citation if available\n",
    "                            for annotation in annotations: \n",
    "                                agent_msg += extract_search_annotation(annotation, text_value_str)\n",
    "                        else:\n",
    "                            agent_msg += text_value_str\n",
    "                            \n",
    "                    elif isinstance(chunk, MessageDeltaImageFileContent):\n",
    "                        file_id = chunk[\"image_file\"].get(\"file_id\", \"\")\n",
    "                        byte_stream = project_client.agents.files.get_content(file_id=file_id)\n",
    "                        # Encode to base64\n",
    "                        # Join all bytes from the iterator\n",
    "                        image_bytes = b\"\".join(byte_stream)\n",
    "                        b64_image = base64.b64encode(image_bytes).decode(\"utf-8\")\n",
    "                        # Use Markdown to display the image in Gradio\n",
    "                        agent_msg += f\"![image](data:image/png;base64,{b64_image})\"  \n",
    "\n",
    "                message_id = event_data[\"id\"]\n",
    "\n",
    "                # Try to find a matching assistant bubble\n",
    "                matching_msg = None\n",
    "                for msg in reversed(conversation):\n",
    "                    if msg.metadata and msg.metadata.get(\"id\") == message_id and msg.role == \"assistant\":\n",
    "                        matching_msg = msg\n",
    "                        break\n",
    "\n",
    "                if matching_msg:\n",
    "                    # Append newly streamed text\n",
    "                    matching_msg.content += agent_msg\n",
    "                else:\n",
    "                    # Append to last assistant or create new\n",
    "                    if (\n",
    "                        not conversation\n",
    "                        or conversation[-1].role != \"assistant\"\n",
    "                        or (\n",
    "                            conversation[-1].metadata\n",
    "                            and str(conversation[-1].metadata.get(\"id\", \"\")).startswith(\"tool-\")\n",
    "                        )\n",
    "                    ):\n",
    "                        conversation.append(ChatMessage(role=\"assistant\", content=agent_msg))\n",
    "                    else:\n",
    "                        conversation[-1].content += agent_msg\n",
    "\n",
    "                yield conversation, \"\"\n",
    "\n",
    "            # 4) If entire assistant message is completed\n",
    "            elif event_type == \"thread.message\":\n",
    "                if event_data[\"role\"] == \"assistant\" and event_data[\"status\"] == \"completed\":\n",
    "                    for cid, msg_obj in in_progress_tools.items():\n",
    "                        msg_obj.metadata[\"status\"] = \"done\"\n",
    "                    in_progress_tools.clear()\n",
    "                    partial_calls_by_id.clear()\n",
    "                    partial_calls_by_index.clear()\n",
    "                    call_id_for_index.clear()\n",
    "                    yield conversation, \"\"\n",
    "\n",
    "            # 5) Final done\n",
    "            elif event_type == \"thread.message.completed\":\n",
    "                for cid, msg_obj in in_progress_tools.items():\n",
    "                    msg_obj.metadata[\"status\"] = \"done\"\n",
    "                in_progress_tools.clear()\n",
    "                partial_calls_by_id.clear()\n",
    "                partial_calls_by_index.clear()\n",
    "                call_id_for_index.clear()\n",
    "                yield conversation, \"\"\n",
    "                break\n",
    "\n",
    "    return conversation, \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a Gradio UI\n",
    "Create a Gradio interface for interacting with the enterprise agent. \n",
    "Include a chatbot component and a text input box for user queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note:\n",
      "tool calling may fail, close the chat with trash bin icon (ðŸ—‘ï¸) and rerun the prompt.\n",
      "\n",
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "brand_theme = gr.themes.Default(\n",
    "    primary_hue=\"blue\",\n",
    "    secondary_hue=\"blue\",\n",
    "    neutral_hue=\"gray\",\n",
    "    font=[\"Segoe UI\", \"Arial\", \"sans-serif\"],\n",
    "    font_mono=[\"Courier New\", \"monospace\"],\n",
    "    text_size=\"lg\",\n",
    ").set(\n",
    "    button_primary_background_fill=\"#0f6cbd\",\n",
    "    button_primary_background_fill_hover=\"#115ea3\",\n",
    "    button_primary_background_fill_hover_dark=\"#4f52b2\",\n",
    "    button_primary_background_fill_dark=\"#5b5fc7\",\n",
    "    button_primary_text_color=\"#ffffff\",\n",
    "    button_secondary_background_fill=\"#e0e0e0\",\n",
    "    button_secondary_background_fill_hover=\"#c0c0c0\",\n",
    "    button_secondary_background_fill_hover_dark=\"#a0a0a0\",\n",
    "    button_secondary_text_color=\"#000000\",\n",
    "    body_background_fill=\"#f5f5f5\",\n",
    "    block_background_fill=\"#ffffff\",\n",
    "    body_text_color=\"#242424\",\n",
    "    body_text_color_subdued=\"#616161\",\n",
    "    block_border_color=\"#d1d1d1\",\n",
    "    block_border_color_dark=\"#333333\",\n",
    "    input_background_fill=\"#ffffff\",\n",
    "    input_border_color=\"#d1d1d1\",\n",
    "    input_border_color_focus=\"#0f6cbd\",\n",
    ")\n",
    "\n",
    "with gr.Blocks(theme=brand_theme, css=\"footer {visibility: hidden;}\", fill_height=True) as demo:\n",
    "\n",
    "    def clear_thread():\n",
    "        global thread\n",
    "        thread = project_client.agents.threads.create()\n",
    "        return []\n",
    "\n",
    "    def on_example_clicked(evt: gr.SelectData):\n",
    "        return evt.value[\"text\"]  # Fill the textbox with that example text\n",
    "\n",
    "    gr.HTML(\"<h1 style=\\\"text-align: center;\\\">Azure AI Agent Service</h1>\")\n",
    "\n",
    "    chatbot = gr.Chatbot(\n",
    "        type=\"messages\",\n",
    "        examples=[\n",
    "            # {\"text\": \"What's my company's remote work policy?\"},\n",
    "            # {\"text\": \"Check if it will rain tomorrow?\"},\n",
    "            # {\"text\": \"How is Contoso's stock doing today?\"},\n",
    "            # {\"text\": \"Show a summary of the all HR policy.\"},\n",
    "            # {\"text\": \"What is the date today?\"},\n",
    "            {\"text\": \"What is the latest news about Microsoft?\"},\n",
    "            # {\"text\": \"How does microsoft do quantum computing?\"},\n",
    "            # {\"text\": \"what is the latest approach of microsoft to do quantum computing?\"},\n",
    "            {\"text\": \"summarize siemens fiscal report 2024 from my company source\"},\n",
    "            # {\"text\": \"Hight 5 insight regarding Microsoft Fiscal Report 2025 Q3.\"},\n",
    "        ],\n",
    "        show_label=False,\n",
    "        scale=1,\n",
    "    )\n",
    "\n",
    "    textbox = gr.Textbox(\n",
    "        show_label=False,\n",
    "        lines=1,\n",
    "        submit_btn=True,\n",
    "    )\n",
    "\n",
    "    # Populate textbox when an example is clicked\n",
    "    chatbot.example_select(fn=on_example_clicked, inputs=None, outputs=textbox)\n",
    "\n",
    "    # On submit: call azure_enterprise_chat, then clear the textbox\n",
    "    (textbox\n",
    "     .submit(\n",
    "         fn=azure_enterprise_chat,\n",
    "         inputs=[textbox, chatbot],\n",
    "         outputs=[chatbot, textbox],\n",
    "     )\n",
    "     .then(\n",
    "         fn=lambda: \"\",\n",
    "         outputs=textbox,\n",
    "     )\n",
    "    )\n",
    "\n",
    "    # A \"Clear\" button that resets the thread and the Chatbot\n",
    "    chatbot.clear(fn=clear_thread, outputs=chatbot)\n",
    "\n",
    "# Launch your Gradio app\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Note:\\ntool calling may fail, close the chat with trash bin icon (ðŸ—‘ï¸) and rerun the prompt.\\n\")\n",
    "    demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) delete agent, thread, and vector store resources\n",
    "Uncomment out the next cell block to delete the resources created in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from azure.identity import DefaultAzureCredential\n",
    "# from azure.ai.projects import AIProjectClient\n",
    "# import os\n",
    "\n",
    "# credential = DefaultAzureCredential()\n",
    "# project_client_delete = AIProjectClient(\n",
    "#    credential=credential,\n",
    "#    endpoint=os.environ.get(\"PROJECT_ENDPOINT\")\n",
    "# )\n",
    "\n",
    "# try:\n",
    "#    project_client_delete.agents.delete_agent(agent.id)\n",
    "#    print(\"Agent deletion successful.\")\n",
    "#    project_client_delete.agents.threads.delete(thread.id)\n",
    "#    print(\"Thread deletion successful.\")\n",
    "#    project_client_delete.agents.vector_stores.delete(vector_store_id)\n",
    "#    print(\"Vector store deletion successful.\")\n",
    "#    print(\"All deletions succeeded.\")\n",
    "# except Exception as e:\n",
    "#    print(f\"Error during deletion: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status > queued\n",
      "status > queued\n",
      "status > in_progress\n",
      "tool_calls > in_progress\n",
      "tool_calls > in_progress\n",
      "tool_calls > completed\n",
      "message_creation > in_progress\n",
      "message_creation > in_progress\n",
      "in_progress (id: msg_bhMzrAs2PtvA7yNAf1MK1dWh)\n",
      "in_progress (id: msg_bhMzrAs2PtvA7yNAf1MK1dWh)\n",
      "\n",
      "assistant > Here is a summary of the Siemens fiscal report for 2024 based on the company source:\n",
      "\n",
      "- Siemens achieved a historic high net income of â‚¬9.0 billion, with basic earnings per share (EPS) increasing to â‚¬10.53. The EPS before purchase price allocation (pre PPA) was â‚¬11.15, reflecting strong profitability.\n",
      "- The return on capital employed (ROCE) rose to 19.1%, driven by higher net income, aligning with Siemens' target range of 15% to 20%.\n",
      "- Capital structure remained strong with the ratio of industrial net debt to EBITDA at 0.7, well within the forecast target of up to 1.5.\n",
      "- Free cash flow was excellent at â‚¬9.5 billion, slightly below the record â‚¬10.0 billion of the previous year.\n",
      "- Business segments showed varied profit margins, with Digital Industries leading among industrial businesses despite a notable decline to 18.9%. Mobility improved its margin to 8.9%, and Siemens Financial Services (SFS) saw significant growth with a return on equity after tax of 17.6%.\n",
      "- A key transaction impacting the financials was an 8% stake transfer in Siemens Energy AG to Siemens Pension-Trust e.V., resulting in a gain of â‚¬0.5 billion.\n",
      "- Orders and revenues showed a book-to-bill ratio of 1.11, and currency effects slightly impacted revenue growth.\n",
      "- Siemens maintains a comprehensive financial performance system focused on revenue growth of 5% to 7% over a medium term and managing comparable growth net of currency translation impacts.\n",
      "\n",
      "Overall, Siemens delivered strong financial results in fiscal 2024, with significant improvements in profitability, capital efficiency, and cash flow, meeting or exceeding their financial forecasts and targets.ã€5:1â€ Siemens fiscal report 2024ã€‘ã€5:3â€ Siemens fiscal report 2024ã€‘ã€5:4â€ Siemens fiscal report 2024ã€‘. If you need a more detailed breakdown of specific segments or financial metrics, please let me know.\n",
      "status > queued\n",
      "status > queued\n",
      "status > in_progress\n",
      "tool_calls > in_progress\n",
      "tool_calls > in_progress\n",
      "tool_calls > completed\n",
      "message_creation > in_progress\n",
      "message_creation > in_progress\n",
      "in_progress (id: msg_GlAhN8uQjJuxKjOg3JXMKf7h)\n",
      "in_progress (id: msg_GlAhN8uQjJuxKjOg3JXMKf7h)\n",
      "\n",
      "assistant > The latest news about Microsoft is that the company is undergoing a major restructuring and cutting around 9,000 jobs, which is about 4% of its global workforce. This is part of a broader restructuring push to streamline operations and reduce management layers despite the company reporting strong financial performance, including $26 billion in net income in the March quarter. These layoffs span multiple teams and locations and are part of a series of job cuts that started earlier in the year, with over 15,000 total layoffs in 2025 so far. This move is believed to be linked to the evolving roles of developers and increasing adoption of AI and automation tools within the company.\n",
      "\n",
      "Microsoft is focusing on organizational changes to position itself for success in a dynamic marketplace, with the cuts affecting professionals across various experience levels and departments. This is the company's second largest mass layoff after a cut of nearly 18,000 jobs in 2014.\n",
      "\n",
      "In contrast, other tech giants like Meta are aggressively hiring AI talent, showing different strategic directions within the tech industry. Microsoft's stock remains strong despite these layoffs, reflecting confidence in its long-term growth and leadership in AI research and development.\n",
      "\n",
      "If you'd like more details or specific aspects of this news, please let me know!ã€3:0â€ 3:4â€ sourceã€‘\n"
     ]
    }
   ],
   "source": [
    "# existing_stores = project_client_delete.agents.vector_stores.list()\n",
    "# for store in existing_stores:\n",
    "#     project_client_delete.agents.vector_stores.delete(store.id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azfdydemo3.12pip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
