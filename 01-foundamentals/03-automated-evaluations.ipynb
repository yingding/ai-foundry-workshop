{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate AI agents of Foundry Agent Services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "\n",
    "This sample demonstrates how to evaluate an AI agent (Azure AI Agent Service) on these important aspects of your agentic workflow:\n",
    "\n",
    "- Intent Resolution: Measures how well the agent identifies the user’s request, including how well it scopes the user’s intent, asks clarifying questions, and reminds end users of its scope of capabilities.\n",
    "\n",
    "For AI agents outside of Azure AI Agent Service, you can still provide th agent data in the two formats (either simple data or agent messages) specified in the individual evaluator samples:\n",
    "- [Intent resolution](https://aka.ms/intentresolution-sample)\n",
    "<!--\n",
    "- [Tool call accuracy](https://aka.ms/toolcallaccuracy-sample)\n",
    "- [Task adherence](https://aka.ms/taskadherence-sample)\n",
    "- [Response Completeness](https://aka.ms/rescompleteness-sample)\n",
    "-->\n",
    "\n",
    "\n",
    "## Time \n",
    "\n",
    "You should expect to spend about 20 minutes running this notebook. \n",
    "\n",
    "## Before you begin\n",
    "Creating an agent using Azure AI agent service requires an Azure AI Foundry project and a deployed, supported model. See more details in [Create a new agent](https://learn.microsoft.com/azure/ai-services/agents/quickstart?pivots=ai-foundry-portal).\n",
    "\n",
    "For quality evaluation, you need to deploy a `gpt` model supporting JSON mode. We recommend a model `gpt-4o` or `gpt-4o-mini` for their strong reasoning capabilities.    \n",
    "\n",
    "Important: Make sure to authenticate to Azure using `az login` in your terminal before running this notebook.\n",
    "\n",
    "### Prerequisite\n",
    "\n",
    "Before running the sample:\n",
    "```bash\n",
    "pip install azure-ai-projects azure-identity azure-ai-evaluation\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Azure credentials and project \n",
    "1. use az cli to login to the tenant with your credential\n",
    "\n",
    "<!-- initializing Project Client -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment and authentication OK\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# load environment variables from .env file\n",
    "load_dotenv(dotenv_path=\".env\", override=True)\n",
    "\n",
    "from utils.fdyauth import AuthHelper\n",
    "settings = AuthHelper.load_settings()\n",
    "credential = AuthHelper.test_credential()\n",
    "\n",
    "if credential:\n",
    "    print('Environment and authentication OK')\n",
    "else:\n",
    "    print(\"please login first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project_client api version: 2025-05-15-preview\n",
      "azure-ai-agents version: 1.1.0b3\n",
      "azure-ai-projects version: 1.0.0b12\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import azure.ai.agents as agentslib\n",
    "import azure.ai.projects as projectslib\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.projects.models import (\n",
    "    AgentEvaluationRequest,\n",
    "    InputDataset,\n",
    "    EvaluatorIds,\n",
    "    EvaluatorConfiguration,\n",
    "    AgentEvaluationSamplingConfiguration,\n",
    "    AgentEvaluationRedactionConfiguration,\n",
    "    Evaluation,\n",
    "    DatasetVersion,\n",
    "    FileDatasetVersion,\n",
    ")\n",
    "from azure.ai.agents.models import (\n",
    "    FunctionTool,\n",
    "    ToolSet,\n",
    "    MessageRole,\n",
    ")\n",
    "\n",
    "# Import your custom functions to be used as Tools for the Agent\n",
    "from utils.user_functions import user_functions\n",
    "\n",
    "# Initialize project client with proper authentication\n",
    "project_client = AIProjectClient(\n",
    "    credential=credential,  # Use the credential from earlier setup\n",
    "    endpoint=settings.project_endpoint\n",
    ")\n",
    "print(\"project_client api version:\", project_client._config.api_version)\n",
    "print(f\"azure-ai-agents version: {agentslib.__version__}\")\n",
    "print(f\"azure-ai-projects version: {projectslib.__version__}\")\n",
    "\n",
    "AGENT_NAME = \"Seattle Tourist Agent\"\n",
    "AGENT_INSTRUCTIONS = \"\"\"You are a helpful tourist assistant\"\"\"\n",
    "\n",
    "# Add Tools to be used by Agent\n",
    "functions = FunctionTool(user_functions)\n",
    "\n",
    "toolset = ToolSet()\n",
    "toolset.add(functions)\n",
    "\n",
    "# To enable tool calls executed automatically\n",
    "project_client.agents.enable_auto_function_calls(tools=toolset, max_retry=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an AI agent (Azure AI Agent Service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reusing agent > Seattle Tourist Agent (id: asst_rs0qLwEnvDVyoxWkp740d8S8)\n"
     ]
    }
   ],
   "source": [
    "found_agent = None\n",
    "all_agents_list = project_client.agents.list_agents()\n",
    "for a in all_agents_list:\n",
    "    if a.name == AGENT_NAME:\n",
    "        found_agent = a\n",
    "        break\n",
    "\n",
    "if found_agent:\n",
    "    agent = project_client.agents.update_agent(\n",
    "        agent_id=found_agent.id,\n",
    "        model=settings.model_deployment_name,\n",
    "        instructions=AGENT_INSTRUCTIONS,\n",
    "        toolset=toolset,\n",
    "    )\n",
    "    project_client.agents.enable_auto_function_calls(tools=toolset, max_retry=4) \n",
    "    print(f\"reusing agent > {agent.name} (id: {agent.id})\")\n",
    "else:\n",
    "    agent = project_client.agents.create_agent(\n",
    "        model=settings.model_deployment_name,\n",
    "        name=AGENT_NAME,\n",
    "        instructions=AGENT_INSTRUCTIONS,\n",
    "        toolset=toolset,\n",
    "    )\n",
    "    print(f\"Created agent '{AGENT_NAME}' with {len(functions._functions)} tools\\nID: {agent.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversation with Agent\n",
    "Use below cells to have conversation with the agent\n",
    "1. `Create a thread`\n",
    "2. `Create Message`\n",
    "3. `Execute`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Thread - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created thread, ID: thread_CwuvWVkYl5PomvD7Kh9X9twE\n"
     ]
    }
   ],
   "source": [
    "thread = project_client.agents.threads.create()\n",
    "print(f\"Created thread, ID: {thread.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Message - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created message, ID: msg_Qjq9lnb0mDA9RK5sfUGiWPHR\n"
     ]
    }
   ],
   "source": [
    "# Create a new user message and add it to the thread (state)\n",
    "MESSAGE = \"Can you email me weather info for Seattle ? My email is user@microsoft.com.\"\n",
    "# MESSAGE = \"Can you email me weather info for Seattle ?\"\n",
    "\n",
    "message = project_client.agents.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=MessageRole.USER,\n",
    "    content=MESSAGE,\n",
    ")\n",
    "print(f\"Created message, ID: {message.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending email to user@microsoft.com...\n",
      "Subject: Weather Information for Seattle\n",
      "Body:\n",
      "The current weather in Seattle is rainy with a temperature of 14°C.\n",
      "Run finished with status: RunStatus.COMPLETED\n",
      "Run ID: run_dakWQEiHPPWoECDmrCKN0KXh\n"
     ]
    }
   ],
   "source": [
    "run = project_client.agents.runs.create_and_process(thread_id=thread.id, agent_id=agent.id)\n",
    "\n",
    "print(f\"Run finished with status: {run.status}\")\n",
    "\n",
    "if run.status == \"failed\":\n",
    "    print(f\"Run failed: {run.last_error}\")\n",
    "\n",
    "print(f\"Run ID: {run.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role: MessageRole.USER\n",
      "Content: Can you email me weather info for Seattle ? My email is user@microsoft.com.\n",
      "----------------------------------------\n",
      "Role: MessageRole.AGENT\n",
      "Content: I have sent the weather information for Seattle to your email (user@microsoft.com). If you need any more information or assistance, feel free to ask!\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for message in project_client.agents.messages.list(thread.id, order=\"asc\"):\n",
    "    print(f\"Role: {message.role}\")\n",
    "    print(f\"Content: {message.content[0].text.value}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation in the cloud\n",
    "\n",
    "Reference:\n",
    "* https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/develop/cloud-evaluation\n",
    "* https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/develop/cloud-evaluation#prerequisite-set-up-steps-for-azure-ai-foundry-projects\n",
    "\n",
    "For the Microsoft Entra ID, give MSI (Microsoft Identity) permissions for \"Storage Blob Data Owner\" through IAM to both\n",
    "* `User, group, or service principal` \"EntraID user\" and\n",
    "* `Managed Identity` by adding the Role its `Azure AI Foundry Project`\n",
    "from the storage account IAM.\n",
    "* And make sure to choose \"Share to all project\" while adding the storage account connection to the Azure AI Foundry Project v2\n",
    "* Blob Storage need to have public network access, so that foundry project can upload the blob file\n",
    "\n",
    "<!--\n",
    "Adding additional `Azure AI Administrator Role` to the Microsoft EntraID User for the `Azure AI Foundry Resource`\n",
    "\n",
    "* `Managed Identity` by adding the Role to both `Azure AI Foundry Resource` and its `Azure AI Foundry Project`\n",
    "from the storage account IAM.\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data from agent response for evaluation\n",
    "\n",
    "Reference:\n",
    "* https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/develop/agent-evaluate-sdk#evaluate-azure-ai-agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AIAgentConverter: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class FDPAgentDataRetriever: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AIAgentDataRetriever: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': [{'role': 'system', 'content': 'You are a helpful tourist assistant'}, {'createdAt': '2025-07-07T13:18:52Z', 'role': 'user', 'content': [{'type': 'text', 'text': 'Can you email me weather info for Seattle ? My email is user@microsoft.com.'}]}], 'response': [{'createdAt': '2025-07-07T13:18:54Z', 'run_id': 'run_dakWQEiHPPWoECDmrCKN0KXh', 'role': 'assistant', 'content': [{'type': 'tool_call', 'tool_call_id': 'call_l41AzZ6R0lp6XcW6l8DiefkQ', 'name': 'fetch_weather', 'arguments': {'location': 'Seattle'}}]}, {'createdAt': '2025-07-07T13:18:56Z', 'run_id': 'run_dakWQEiHPPWoECDmrCKN0KXh', 'tool_call_id': 'call_l41AzZ6R0lp6XcW6l8DiefkQ', 'role': 'tool', 'content': [{'type': 'tool_result', 'tool_result': {'weather': 'Rainy, 14°C'}}]}, {'createdAt': '2025-07-07T13:18:57Z', 'run_id': 'run_dakWQEiHPPWoECDmrCKN0KXh', 'role': 'assistant', 'content': [{'type': 'tool_call', 'tool_call_id': 'call_JSp5z9K7V9659si36p16Jsjx', 'name': 'send_email', 'arguments': {'recipient': 'user@microsoft.com', 'subject': 'Weather Information for Seattle', 'body': 'The current weather in Seattle is rainy with a temperature of 14°C.'}}]}, {'createdAt': '2025-07-07T13:18:59Z', 'run_id': 'run_dakWQEiHPPWoECDmrCKN0KXh', 'tool_call_id': 'call_JSp5z9K7V9659si36p16Jsjx', 'role': 'tool', 'content': [{'type': 'tool_result', 'tool_result': {'message': 'Email successfully sent to user@microsoft.com.'}}]}, {'createdAt': '2025-07-07T13:18:59Z', 'run_id': 'run_dakWQEiHPPWoECDmrCKN0KXh', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'I have sent the weather information for Seattle to your email (user@microsoft.com). If you need any more information or assistance, feel free to ask!'}]}], 'tool_definitions': [{'name': 'get_user_info', 'type': 'function', 'description': 'Retrieves user information based on user ID.', 'parameters': {'type': 'object', 'properties': {'user_id': {'type': 'integer', 'description': 'ID of the user.'}}}}, {'name': 'convert_temperature', 'type': 'function', 'description': 'Converts temperature from Celsius to Fahrenheit.', 'parameters': {'type': 'object', 'properties': {'celsius': {'type': 'number', 'description': 'Temperature in Celsius.'}}}}, {'name': 'send_email', 'type': 'function', 'description': 'Sends an email with the specified subject and body to the recipient.', 'parameters': {'type': 'object', 'properties': {'recipient': {'type': 'string', 'description': 'Email address of the recipient.'}, 'subject': {'type': 'string', 'description': 'Subject of the email.'}, 'body': {'type': 'string', 'description': 'Body content of the email.'}}}}, {'name': 'longest_word_in_sentences', 'type': 'function', 'description': 'Finds the longest word in each sentence.', 'parameters': {'type': 'object', 'properties': {'sentences': {'type': 'array', 'items': {'type': 'string'}, 'description': 'A list of sentences.'}}}}, {'name': 'merge_dicts', 'type': 'function', 'description': 'Merges two dictionaries.', 'parameters': {'type': 'object', 'properties': {'dict1': {'type': 'object', 'description': 'First dictionary.'}, 'dict2': {'type': 'object', 'description': 'Second dictionary.'}}}}, {'name': 'toggle_flag', 'type': 'function', 'description': 'Toggles a boolean flag.', 'parameters': {'type': 'object', 'properties': {'flag': {'type': 'boolean', 'description': 'The flag to toggle.'}}}}, {'name': 'fetch_weather', 'type': 'function', 'description': 'Fetches the weather information for the specified location.', 'parameters': {'type': 'object', 'properties': {'location': {'type': 'string', 'description': 'The location to fetch weather for.'}}}}, {'name': 'process_records', 'type': 'function', 'description': 'Process a list of records, where each record is a dictionary with string keys and integer values.', 'parameters': {'type': 'object', 'properties': {'records': {'type': 'array', 'items': {'type': 'object'}, 'description': 'A list containing dictionaries that map strings to integers.'}}}}, {'name': 'fetch_current_datetime', 'type': 'function', 'description': 'Get the current time as a JSON string, optionally formatted.', 'parameters': {'type': 'object', 'properties': {'format': {'type': ['string', 'null'], 'description': 'The format in which to return the current time. Defaults to None, which uses a standard format.'}}}}, {'name': 'calculate_sum', 'type': 'function', 'description': 'Calculates the sum of two integers.', 'parameters': {'type': 'object', 'properties': {'a': {'type': 'integer', 'description': 'First integer.'}, 'b': {'type': 'integer', 'description': 'Second integer.'}}}}, {'name': 'opening_hours', 'type': 'function', 'description': 'Fetches the opening hours of a tourist destination in Seattle.', 'parameters': {'type': 'object', 'properties': {'tourist_destination': {'type': 'string', 'description': 'The tourist destination to fetch opening hours for.'}}}}]}\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import AIAgentConverter\n",
    "import json\n",
    "\n",
    "# Initialize the converter that will be backed by the project.\n",
    "converter = AIAgentConverter(project_client)\n",
    "\n",
    "thread_id = thread.id\n",
    "run_id = run.id\n",
    "\n",
    "# Get a single agent run data for evaluation\n",
    "single_agent_eval_input_data = converter.convert(thread_id=thread_id, run_id=run_id)\n",
    "\n",
    "# make folder\n",
    "dir_path = os.path.join(os.getcwd(), \"data\")\n",
    "if not os.path.exists(dir_path):\n",
    "    os.makedirs(dir_path)\n",
    "\n",
    "# Save the agent run data to a JSONL file\n",
    "# eval_file_name = f\"single_agent_eval_{thread_id}_{run_id}.jsonl\"\n",
    "eval_file_name = f\"singleagentrun.jsonl\"\n",
    "eval_file_path = os.path.join(os.getcwd(), \"data\", eval_file_name)\n",
    "\n",
    "print(single_agent_eval_input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Can you email me weather info for Seattle ? My email is user@microsoft.com.',\n",
       " 'ground_truth': 'yes, I mailed you the weather info for Seattle',\n",
       " 'response': 'I have sent the weather information for Seattle to your email (user@microsoft.com). If you need any more information or assistance, feel free to ask!',\n",
       " 'context': 'You are a helpful tourist assistant',\n",
       " 'latency': 8.5,\n",
       " 'response_length': 149}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.converter import extract_agent_data\n",
    "eval_input = extract_agent_data(single_agent_eval_input_data, ground_truth=\"yes, I mailed you the weather info for Seattle\")\n",
    "eval_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the the whole object of single_agent_eval_input_data to the eval_file_path as jsonl entry\n",
    "# how to append to existing file\n",
    "with open(eval_file_path, \"w\") as f:\n",
    "    f.write(json.dumps(eval_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AI Foundry Cloud Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a timestamp of now\n",
    "import datetime\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload a single file and create a new Dataset to reference the file.\n",
      "Dataset: singleagent-20250707151622, Version: 1.0, ID: azureai://accounts/foundry-proj-yw-uno-resource/projects/foundry-proj-yw-uno/data/singleagent-20250707151622/versions/1.0\n",
      "Dataset: singleagent-20250707151228, Version: 1.0, ID: azureai://accounts/foundry-proj-yw-uno-resource/projects/foundry-proj-yw-uno/data/singleagent-20250707151228/versions/1.0\n",
      "Dataset: singleagent-20250707150913, Version: 1.0, ID: azureai://accounts/foundry-proj-yw-uno-resource/projects/foundry-proj-yw-uno/data/singleagent-20250707150913/versions/1.0\n",
      "Dataset: singleagent-20250707150742, Version: 1.0, ID: azureai://accounts/foundry-proj-yw-uno-resource/projects/foundry-proj-yw-uno/data/singleagent-20250707150742/versions/1.0\n",
      "Dataset: singleagent-20250707142357, Version: 1.0, ID: azureai://accounts/foundry-proj-yw-uno-resource/projects/foundry-proj-yw-uno/data/singleagent-20250707142357/versions/1.0\n",
      "Dataset: singleagent-20250707135213, Version: 1.0, ID: azureai://accounts/foundry-proj-yw-uno-resource/projects/foundry-proj-yw-uno/data/singleagent-20250707135213/versions/1.0\n",
      "Dataset: singleagent-20250707132440, Version: 1.0, ID: azureai://accounts/foundry-proj-yw-uno-resource/projects/foundry-proj-yw-uno/data/singleagent-20250707132440/versions/1.0\n",
      "Dataset: singleagent-20250707130907, Version: 1.0, ID: azureai://accounts/foundry-proj-yw-uno-resource/projects/foundry-proj-yw-uno/data/singleagent-20250707130907/versions/1.0\n",
      "Dataset: singleagentdemo1, Version: 1.0, ID: azureai://accounts/foundry-proj-yw-uno-resource/projects/foundry-proj-yw-uno/data/singleagentdemo1/versions/1.0\n",
      "Dataset: sigleagentrun, Version: 1.0, ID: azureai://accounts/foundry-proj-yw-uno-resource/projects/foundry-proj-yw-uno/data/sigleagentrun/versions/1.0\n",
      "Dataset: tourist-single-agent-dataset-1, Version: 2.0, ID: azureai://accounts/foundry-proj-yw-uno-resource/projects/foundry-proj-yw-uno/data/tourist-single-agent-dataset-1/versions/2.0\n",
      "Dataset: eval-data-2025-06-25_215535_UTC, Version: 1, ID: azureai://accounts/foundry-proj-yw-uno-resource/projects/foundry-proj-yw-uno/data/eval-data-2025-06-25_215535_UTC/versions/1\n",
      "Dataset: tourist-test-dataset, Version: 1.0, ID: azureai://accounts/foundry-proj-yw-uno-resource/projects/foundry-proj-yw-uno/data/tourist-test-dataset/versions/1.0\n",
      "Dataset: eval-data-2025-06-25_213617_UTC, Version: 1, ID: azureai://accounts/foundry-proj-yw-uno-resource/projects/foundry-proj-yw-uno/data/eval-data-2025-06-25_213617_UTC/versions/1\n",
      "{'id': 'azureai://accounts/foundry-proj-yw-uno-resource/projects/foundry-proj-yw-uno/data/singleagent-20250707152046/versions/1.0', 'name': 'singleagent-20250707152046', 'version': '1.0', 'displayName': 'singleagent-20250707152046', 'description': None, 'tags': {}, 'type': 'uri_file', 'isReference': False, 'dataUri': 'https://stacctaievalywuno.blob.core.windows.net/foundry-pr-e1020690-0860-56bf-9aac-a1de83224422/singleagentrun.jsonl', 'connectionName': None, 'systemData': {'createdAt': '2025-07-07T13:20:53.2549577+00:00', 'createdBy': 'Yingding Wang', 'createdByType': None, 'lastModifiedAt': '2025-07-07T13:20:53.2549577+00:00'}}\n"
     ]
    }
   ],
   "source": [
    "print(\"Upload a single file and create a new Dataset to reference the file.\")\n",
    "dataset_name = f\"singleagent-{timestamp}\"\n",
    "dataset_version = \"1.0\"\n",
    "\n",
    "existing_datasets = project_client.datasets.list()\n",
    "map = {}\n",
    "for dataset in existing_datasets:\n",
    "    # print(f\"Dataset:{dataset}\")\n",
    "    print(f\"Dataset: {dataset.name}, Version: {dataset.version}, ID: {dataset.id}\")\n",
    "    map[dataset.name] = dataset.id\n",
    "\n",
    "if dataset_name in map:\n",
    "    print(f\"Dataset {dataset_name} already exists with ID: {map[dataset_name]}\")\n",
    "    project_client.datasets.delete(name=dataset_name, version=dataset_version)\n",
    "    print(f\"Deleted existing dataset {dataset_name} with version {dataset_version}\")\n",
    "\n",
    "# stacctaievalywuno with IAM role \"storage blob data owner\" for the Azure AI Foundry project and Entra ID principal \n",
    "dataset: DatasetVersion = project_client.datasets.upload_file(\n",
    "    name=dataset_name,\n",
    "    version=dataset_version,\n",
    "    file_path=eval_file_path,\n",
    "    connection_name=\"stacctaievalywuno\"\n",
    ")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Textual similarity evaluators\n",
    "\n",
    "* https://learn.microsoft.com/en-us/azure/ai-foundry/concepts/evaluation-evaluators/textual-similarity-evaluators\n",
    "* Config examples https://github.com/Azure-Samples/azureai-samples/blob/main/scenarios/evaluate/Supported_Evaluation_Metrics/AI_Judge_Evaluators_Quality/AI_Judge_Evaluators_Quality.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create an evaluation task\n",
      "{'data': {'id': 'azureai://accounts/foundry-proj-yw-uno-resource/projects/foundry-proj-yw-uno/data/singleagent-20250707152046/versions/1.0', 'type': 'Dataset'}, 'target': None, 'description': 'Evaluation for seattle tourist agent', 'evaluators': {'relevance': {'id': 'azureai://built-in/evaluators/relevance', 'initParams': {'deployment_name': 'gpt-4.1-mini'}, 'dataMapping': {'query': '${data.query}', 'response': '${data.response}'}}, 'violence': {'id': 'azureai://built-in/evaluators/violence', 'initParams': {'azure_ai_project': 'https://foundry-proj-yw-uno-resource.services.ai.azure.com/api/projects/foundry-proj-yw-uno'}, 'dataMapping': {}}, 'bleu_score': {'id': 'azureai://built-in/evaluators/bleu_score', 'initParams': {'threshold': 0.01}, 'dataMapping': {'response': '${data.response}', 'ground_truth': '${data.ground_truth}'}}, 'f1_score': {'id': 'azureai://built-in/evaluators/f1_score', 'initParams': {'threshold': 0.2}, 'dataMapping': {'response': '${data.response}', 'ground_truth': '${data.ground_truth}'}}, 'meteor_score': {'id': 'azureai://built-in/evaluators/meteor_score', 'initParams': {'threshold': 0.4}, 'dataMapping': {'response': '${data.response}', 'ground_truth': '${data.ground_truth}'}}}, 'id': 'f2a176d7-2bae-46e0-a6d8-1b3adc70fdb4', 'displayName': 'Single Agent Eval 20250707152046', 'tags': {}, 'properties': {'runType': 'eval_run', '_azureml.evaluation_run': 'evaluation.service', '_azureml.evaluate_artifacts': '[{\"path\": \"instance_results.jsonl\", \"type\": \"table\"}]', 'AiStudioEvaluationUri': 'https://ai.azure.com/resource/build/evaluation/f2a176d7-2bae-46e0-a6d8-1b3adc70fdb4?wsid=/subscriptions/6753a2ee-12b7-4fac-82fa-48824fb58abe/resourceGroups/rg-ai-sandbox-yw-uno/providers/Microsoft.CognitiveServices/accounts/foundry-proj-yw-uno-resource/projects/foundry-proj-yw-uno&tid=787eb5ff-f2ee-4965-8074-edbba3402c84', '_azureml.evaluation_name_map_length': '1', '_azureml.evaluation_name_map_0': '{\"relevance\":\"relevance\",\"violence\":\"violence\",\"bleu_score\":\"bleu_score\",\"f1_score\":\"f1_score\",\"meteor_score\":\"meteor_score\"}'}, 'status': 'NotStarted', 'outputs': {}, 'systemData': {'createdAt': '07/07/2025 13:44:11 +00:00', 'createdBy': 'Yingding Wang', 'modifiedBy': 'Yingding Wang'}}\n",
      "Get evaluation\n",
      "{'data': {'id': 'azureai://accounts/foundry-proj-yw-uno-resource/projects/foundry-proj-yw-uno/data/singleagent-20250707152046/versions/1.0', 'type': 'Dataset'}, 'target': None, 'description': 'Evaluation for seattle tourist agent', 'evaluators': {'relevance': {'id': 'azureai://built-in/evaluators/relevance', 'initParams': {'deployment_name': 'gpt-4.1-mini'}, 'dataMapping': {'query': '${data.query}', 'response': '${data.response}'}}, 'violence': {'id': 'azureai://built-in/evaluators/violence', 'initParams': {'azure_ai_project': 'https://foundry-proj-yw-uno-resource.services.ai.azure.com/api/projects/foundry-proj-yw-uno'}, 'dataMapping': {}}, 'bleu_score': {'id': 'azureai://built-in/evaluators/bleu_score', 'initParams': {'threshold': 0.01}, 'dataMapping': {'response': '${data.response}', 'ground_truth': '${data.ground_truth}'}}, 'f1_score': {'id': 'azureai://built-in/evaluators/f1_score', 'initParams': {'threshold': 0.2}, 'dataMapping': {'response': '${data.response}', 'ground_truth': '${data.ground_truth}'}}, 'meteor_score': {'id': 'azureai://built-in/evaluators/meteor_score', 'initParams': {'threshold': 0.4}, 'dataMapping': {'response': '${data.response}', 'ground_truth': '${data.ground_truth}'}}}, 'id': 'f2a176d7-2bae-46e0-a6d8-1b3adc70fdb4', 'displayName': 'Single Agent Eval 20250707152046', 'tags': {}, 'properties': {'runType': 'eval_run', '_azureml.evaluation_run': 'evaluation.service', '_azureml.evaluate_artifacts': '[{\"path\": \"instance_results.jsonl\", \"type\": \"table\"}]', 'AiStudioEvaluationUri': 'https://ai.azure.com/resource/build/evaluation/f2a176d7-2bae-46e0-a6d8-1b3adc70fdb4?wsid=/subscriptions/6753a2ee-12b7-4fac-82fa-48824fb58abe/resourceGroups/rg-ai-sandbox-yw-uno/providers/Microsoft.CognitiveServices/accounts/foundry-proj-yw-uno-resource/projects/foundry-proj-yw-uno&tid=787eb5ff-f2ee-4965-8074-edbba3402c84', '_azureml.evaluation_name_map_length': '1', '_azureml.evaluation_name_map_0': '{\"relevance\":\"relevance\",\"violence\":\"violence\",\"bleu_score\":\"bleu_score\",\"f1_score\":\"f1_score\",\"meteor_score\":\"meteor_score\"}'}, 'status': 'Starting', 'outputs': {'evaluationResultId': ''}, 'systemData': {'createdAt': '07/07/2025 13:44:11 +00:00', 'createdBy': 'Yingding Wang', 'modifiedBy': 'Yingding Wang'}}\n",
      "List evaluations\n",
      "Single Agent Eval 20250707152046:\n",
      "Single Agent Eval 20250707151622:\n",
      "Single Agent Eval 20250707151228:\n",
      "Single Agent Eval 20250707150913:\n",
      "Single Agent Eval 20250707150742:\n",
      "Single Agent Eval 20250707142357:\n",
      "Single Agent Eval 20250707135213:\n",
      "Single Agent Eval 20250707135213:\n",
      "Single Agent Eval 20250707135213:\n",
      "Single Agent Eval 20250707135213:\n",
      "Single Agent Eval 20250707135213:\n",
      "Single Agent Eval 20250707135213:\n",
      "Single Agent Eval 20250707135213:\n",
      "Single Agent Eval 20250707135213:\n",
      "Single Agent Eval 20250707132440:\n",
      "Single Agent Eval 20250707132440:\n",
      "Single Agent Eval 20250707132440:\n",
      "Single Agent Eval 20250707132440:\n",
      "Single Agent Eval 20250707132440:\n",
      "Single Agent Eval 20250707132440:\n",
      "Single Agent Eval 20250707132440:\n",
      "Single Agent Eval 20250707130907:\n",
      "Single Agent Eval {timestamp}:\n",
      "Single Agent Eval {timestamp}:\n",
      "Sample Evaluation Test:\n",
      "evaluation_test2:\n",
      "evaluation_yw_first_test_eval:\n"
     ]
    }
   ],
   "source": [
    "print(\"Create an evaluation task\")\n",
    "evaluation: Evaluation = Evaluation(\n",
    "    display_name=f\"Single Agent Eval {timestamp}\",\n",
    "    description=\"Evaluation for seattle tourist agent\",\n",
    "    # Sample Dataset Id : azureai://accounts/<account_name>/projects/<project_name>/data/<dataset_name>/versions/<version>\n",
    "    data=InputDataset(id=dataset.id if dataset.id else \"\"),\n",
    "    evaluators={\n",
    "        # AI Quality Eval, AI Assisst \n",
    "        \"relevance\": EvaluatorConfiguration(\n",
    "            id=EvaluatorIds.RELEVANCE.value,\n",
    "            init_params={\n",
    "                \"deployment_name\": settings.model_deployment_name,\n",
    "            },\n",
    "            data_mapping={\n",
    "                \"query\": \"${data.query}\",\n",
    "                \"response\": \"${data.response}\",\n",
    "            },\n",
    "        ),\n",
    "        # \"groundedness\": EvaluatorConfiguration(\n",
    "        #     id=EvaluatorIds.GROUNDEDNESS.value,\n",
    "        #     init_params={\n",
    "        #         \"deployment_name\": settings.model_deployment_name,\n",
    "        #     },\n",
    "        #     data_mapping={\n",
    "        #         \"response\": \"${target.response}\",\n",
    "        #         # \"context\": \"${data.context}\",\n",
    "        #         \"query\": \"${data.query}\",\n",
    "        #     },\n",
    "        # ),\n",
    "        # \"fluency\": EvaluatorConfiguration(\n",
    "        #     id=EvaluatorIds.FLUENCY.value,\n",
    "        #     init_params={\n",
    "        #         \"deployment_name\": settings.model_deployment_name,\n",
    "        #     },\n",
    "        #     data_mapping={\n",
    "        #         \"response\": \"${target.response}\",\n",
    "        #         # \"context\": \"${data.context}\",\n",
    "        #         \"query\": \"${data.query}\",\n",
    "        #     },\n",
    "        # ),\n",
    "        # Risks and Safety: content filter\n",
    "        \"violence\": EvaluatorConfiguration(\n",
    "            id=EvaluatorIds.VIOLENCE.value,\n",
    "            init_params={\n",
    "                \"azure_ai_project\": settings.project_endpoint,\n",
    "            },\n",
    "        ),\n",
    "        # \"sexual\": EvaluatorConfiguration(\n",
    "        #     id=EvaluatorIds.SEXUAL.value,\n",
    "        #     init_params={\n",
    "        #         \"azure_ai_project\": settings.project_endpoint,\n",
    "        #     },\n",
    "        # ),\n",
    "        # \"self_harm\": EvaluatorConfiguration(\n",
    "        #     id=EvaluatorIds.SELF_HARM.value,\n",
    "        #     init_params={\n",
    "        #         \"azure_ai_project\": settings.project_endpoint,\n",
    "        #     },\n",
    "        # ),\n",
    "        # text evaluators\n",
    "        \"bleu_score\": EvaluatorConfiguration(\n",
    "            id=EvaluatorIds.BLEU_SCORE.value,\n",
    "            init_params={\n",
    "                \"threshold\": 0.01,\n",
    "            },\n",
    "            data_mapping={\n",
    "                \"response\": \"${data.response}\",\n",
    "                \"ground_truth\": \"${data.ground_truth}\",\n",
    "            },\n",
    "        ),\n",
    "        \"f1_score\": EvaluatorConfiguration(\n",
    "            id=EvaluatorIds.F1_SCORE.value,\n",
    "            init_params={\n",
    "                \"threshold\": 0.2,\n",
    "            },\n",
    "            data_mapping={\n",
    "                \"response\": \"${data.response}\",\n",
    "                \"ground_truth\": \"${data.ground_truth}\",\n",
    "            },\n",
    "        ),\n",
    "        \"meteor_score\": EvaluatorConfiguration(\n",
    "            id=EvaluatorIds.METEOR_SCORE.value,\n",
    "            init_params={\n",
    "                \"threshold\": 0.4,\n",
    "            },\n",
    "            data_mapping={\n",
    "                \"response\": \"${data.response}\",\n",
    "                \"ground_truth\": \"${data.ground_truth}\",\n",
    "            },\n",
    "        ),\n",
    "    },\n",
    ")\n",
    "\n",
    "# Use the model endpoint and API key as AI Evaluator to run the evaluation\n",
    "evaluation_response: Evaluation = project_client.evaluations.create(\n",
    "    evaluation,\n",
    "    headers={\n",
    "        \"model-endpoint\": settings.azure_openai_endpoint,\n",
    "        \"api-key\": settings.azure_openai_api_key,\n",
    "    },\n",
    ")\n",
    "print(evaluation_response)\n",
    "\n",
    "print(\"Get evaluation\")\n",
    "get_evaluation_response: Evaluation = project_client.evaluations.get(evaluation_response.name)\n",
    "\n",
    "print(get_evaluation_response)\n",
    "\n",
    "print(\"List evaluations\")\n",
    "for evaluation in project_client.evaluations.list():\n",
    "    print(f\"{evaluation.display_name}:{evaluation.description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List all evaluations in the project\n",
      "Evaluation ID: Single Agent Eval 20250707152046\n",
      "Evaluation ID: Single Agent Eval 20250707151622\n",
      "Evaluation ID: Single Agent Eval 20250707151228\n",
      "Evaluation ID: Single Agent Eval 20250707150913\n",
      "Evaluation ID: Single Agent Eval 20250707150742\n",
      "Evaluation ID: Single Agent Eval 20250707142357\n",
      "Evaluation ID: Single Agent Eval 20250707135213\n",
      "Evaluation ID: Single Agent Eval 20250707135213\n",
      "Evaluation ID: Single Agent Eval 20250707135213\n",
      "Evaluation ID: Single Agent Eval 20250707135213\n",
      "Evaluation ID: Single Agent Eval 20250707135213\n",
      "Evaluation ID: Single Agent Eval 20250707135213\n",
      "Evaluation ID: Single Agent Eval 20250707135213\n",
      "Evaluation ID: Single Agent Eval 20250707135213\n",
      "Evaluation ID: Single Agent Eval 20250707132440\n",
      "Evaluation ID: Single Agent Eval 20250707132440\n",
      "Evaluation ID: Single Agent Eval 20250707132440\n",
      "Evaluation ID: Single Agent Eval 20250707132440\n",
      "Evaluation ID: Single Agent Eval 20250707132440\n",
      "Evaluation ID: Single Agent Eval 20250707132440\n",
      "Evaluation ID: Single Agent Eval 20250707132440\n",
      "Evaluation ID: Single Agent Eval 20250707130907\n",
      "Evaluation ID: Single Agent Eval {timestamp}\n",
      "Evaluation ID: Single Agent Eval {timestamp}\n",
      "Evaluation ID: Sample Evaluation Test\n",
      "Evaluation ID: evaluation_test2\n",
      "Evaluation ID: evaluation_yw_first_test_eval\n"
     ]
    }
   ],
   "source": [
    "# List all evaluation runs in the project\n",
    "print(\"List all evaluations in the project\")\n",
    "eval_list = project_client.evaluations.list()\n",
    "for eval_item in eval_list:\n",
    "    print(f\"Evaluation ID: {eval_item.display_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Foundry Project Evaluation Metric Dashboard\n",
    "\n",
    "1. Login to `https://ai.azure.com/`\n",
    "2. choose your Foundry Project\n",
    "3. Open the `Evaluation` menu item\n",
    "4. choose an evaluation run to see metric dashboard\n",
    "\n",
    "![](imgs/cloud_eval_metric_dashboard.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azfdydemo3.12pip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
