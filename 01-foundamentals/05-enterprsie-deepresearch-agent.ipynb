{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9a1f690",
   "metadata": {},
   "source": [
    "## Intro Enterprise deep research agent\n",
    "\n",
    "Currently deep research tool doesn't support stream\n",
    "* https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/deep-research-samples\n",
    "* https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/deep-research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "546a9df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment and authentication OK\n"
     ]
    }
   ],
   "source": [
    "from typing import Any, Callable, Set, List, Optional\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.agents import AgentsClient\n",
    "from azure.ai.agents.telemetry import trace_function\n",
    "from azure.ai.agents.models import (\n",
    "    FunctionTool,\n",
    "    RequiredFunctionToolCall,\n",
    "    SubmitToolOutputsAction,\n",
    "    ToolSet,\n",
    "    ToolOutput,\n",
    "    ThreadMessage,\n",
    "    MessageRole,\n",
    "    DeepResearchTool,\n",
    "    ThreadRun,\n",
    ")\n",
    "import azure.ai.agents as agentslib\n",
    "import azure.ai.projects as projectslib\n",
    "from opentelemetry import trace\n",
    "from azure.monitor.opentelemetry import configure_azure_monitor\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# Your custom Python functions (for \"fetch_datetime\", etc.)\n",
    "from utils.enterprise_functions import enterprise_fns\n",
    "\n",
    "load_dotenv(dotenv_path=\".env_westus\", override=True)\n",
    "\n",
    "from utils.fdyauth import AuthHelper\n",
    "settings = AuthHelper.load_settings()\n",
    "credential = AuthHelper.test_credential()\n",
    "\n",
    "if credential:\n",
    "    print('Environment and authentication OK')\n",
    "else:\n",
    "    print(\"please login first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9568866b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project_client api version: 2025-05-15-preview\n",
      "azure-ai-agents version: 1.1.0b3\n",
      "azure-ai-projects version: 1.0.0b12\n"
     ]
    }
   ],
   "source": [
    "# new AI Foundry Project resource endpoint / old azure ai services endpoint from the hub/project\n",
    "project_client = AIProjectClient(\n",
    "    credential=credential,\n",
    "    endpoint=settings.project_endpoint,\n",
    "    # api_version=os.environ[\"PROJECT_API_VERSION\"]\n",
    ")\n",
    "print(\"project_client api version:\", project_client._config.api_version)\n",
    "print(f\"azure-ai-agents version: {agentslib.__version__}\")\n",
    "print(f\"azure-ai-projects version: {projectslib.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed566f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deep research > connected\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    bing_connection = project_client.connections.get(name=settings.bing_connection_name)\n",
    "    # print(f\"{bing_connection}\")\n",
    "    conn_id = bing_connection.id\n",
    "    \n",
    "    deep_research_tool = DeepResearchTool(\n",
    "        bing_grounding_connection_id=conn_id,\n",
    "        deep_research_model=\"o3-deep-research\",\n",
    "    )\n",
    "    print(\"deep research > connected\")\n",
    "except Exception:\n",
    "    bing_tool = None\n",
    "    print(\"deep research failed > no connection found or permission issue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ba9fee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tool > DeepResearchTool\n",
      "tool > FunctionTool\n"
     ]
    }
   ],
   "source": [
    "class LoggingToolSet(ToolSet):\n",
    "    def execute_tool_calls(self, tool_calls: List[Any]) -> List[dict]:\n",
    "        \"\"\"\n",
    "        Execute the upstream calls, printing only two lines per function:\n",
    "        1) The function name + its input arguments\n",
    "        2) The function name + its output result\n",
    "        \"\"\"\n",
    "\n",
    "        # For each function call, print the input arguments\n",
    "        for c in tool_calls:\n",
    "            if hasattr(c, \"function\") and c.function:\n",
    "                fn_name = c.function.name\n",
    "                fn_args = c.function.arguments\n",
    "                print(f\"{fn_name} inputs > {fn_args} (id:{c.id})\")\n",
    "\n",
    "        # Execute the tool calls (superclass logic)\n",
    "        raw_outputs = super().execute_tool_calls(tool_calls)\n",
    "\n",
    "        # Print the output of each function call\n",
    "        for item in raw_outputs:\n",
    "            print(f\"output > {item['output']}\")\n",
    "\n",
    "        return raw_outputs\n",
    "\n",
    "# need an empty toolset to add tools\n",
    "custom_functions = FunctionTool(enterprise_fns)\n",
    "\n",
    "toolset = LoggingToolSet()\n",
    "\n",
    "# if file_search_tool:\n",
    "#      toolset.add(file_search_tool)\n",
    "if deep_research_tool:\n",
    "    toolset.add(deep_research_tool)\n",
    "toolset.add(custom_functions)\n",
    "\n",
    "\n",
    "for tool in toolset._tools:\n",
    "    tool_name = tool.__class__.__name__\n",
    "    print(f\"tool > {tool_name}\")\n",
    "    for definition in tool.definitions:\n",
    "        if hasattr(definition, \"function\"):\n",
    "            fn = definition.function\n",
    "            print(f\"{fn.name} > {fn.description}\")\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8359fb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reusing agent > enterprise-research-agent (id: asst_7lKJLNKtsmqUIhjlM6Zx4sDB)\n"
     ]
    }
   ],
   "source": [
    "# AGENT_NAME = \"enterprise-deepresearch-agent\"\n",
    "AGENT_NAME = settings.agent_name\n",
    "found_agent = None\n",
    "all_agents_list = project_client.agents.list_agents()\n",
    "for a in all_agents_list:\n",
    "    if a.name == AGENT_NAME:\n",
    "        found_agent = a\n",
    "        break\n",
    "\n",
    "model_name = settings.model_deployment_name\n",
    "\n",
    "instructions = (\n",
    "    \"You are a helpful enterprise assistant at Contoso. \"\n",
    "    \"You have access to following tools. \\n\\n\"\n",
    "    \"## Tools:\\n\"\n",
    "    \" * deep_research: get information about company financial reportings\\n\"\n",
    ")\n",
    "\n",
    "project_client.agents.enable_auto_function_calls(tools=toolset, max_retry=4)\n",
    "\n",
    "if found_agent:\n",
    "    # print(found_agent)\n",
    "    # Update the existing agent to use new tools\n",
    "    agent = project_client.agents.update_agent(\n",
    "        agent_id=found_agent.id,\n",
    "        model=model_name,\n",
    "        instructions=instructions,\n",
    "        # tools=deep_research_tool.definitions,\n",
    "        toolset=toolset\n",
    "\n",
    "    )\n",
    "    project_client.agents.enable_auto_function_calls(tools=toolset) \n",
    "    print(f\"reusing agent > {agent.name} (id: {agent.id})\")\n",
    "else:\n",
    "    agent = project_client.agents.create_agent(\n",
    "        model=model_name,\n",
    "        name=AGENT_NAME,\n",
    "        instructions=instructions,\n",
    "        # tools=deep_research_tool.definitions\n",
    "        toolset=toolset,\n",
    "    )\n",
    "    print(f\"creating agent > {agent.name} (id: {agent.id})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8d06f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created thread, ID: thread_zRN6TUHnCh5Ue7jii3p9XONd\n"
     ]
    }
   ],
   "source": [
    "thread = project_client.agents.threads.create()\n",
    "print(f\"Created thread, ID: {thread.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58c1b510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created message, ID: msg_8x0fOTkbXrTdZjv6Zgc0RjW4\n"
     ]
    }
   ],
   "source": [
    "# Create message to thread\n",
    "message = project_client.agents.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=MessageRole.USER,\n",
    "    content=(\n",
    "        \"Give me the latest research into quantum computing over the last year.\"\n",
    "    ),\n",
    ")\n",
    "print(f\"Created message, ID: {message.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29bc6741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yingdingwang\\Documents\\VCS\\democollections\\ai-foundry-workshop\\01-foundamentals\n"
     ]
    }
   ],
   "source": [
    "root_dir = os.path.abspath(os.getcwd())\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5782a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_and_print_new_agent_response(\n",
    "    thread_id: str,\n",
    "    agents_client: AgentsClient,\n",
    "    last_message_id: Optional[str] = None,\n",
    ") -> Optional[str]:\n",
    "    response = agents_client.messages.get_last_message_by_role(\n",
    "        thread_id=thread_id,\n",
    "        role=MessageRole.AGENT,\n",
    "    )\n",
    "    if not response or response.id == last_message_id:\n",
    "        return last_message_id  # No new content\n",
    "\n",
    "    print(\"\\nAgent response:\")\n",
    "    print(\"\\n\".join(t.text.value for t in response.text_messages))\n",
    "\n",
    "    for ann in response.url_citation_annotations:\n",
    "        print(f\"URL Citation: [{ann.url_citation.title}]({ann.url_citation.url})\")\n",
    "\n",
    "    return response.id\n",
    "\n",
    "def create_research_summary(\n",
    "        message : ThreadMessage,\n",
    "        subdir=\"data\", filename: str = \"research_summary.md\"\n",
    ") -> None:\n",
    "    if not message:\n",
    "        print(\"No message content provided, cannot create research summary.\")\n",
    "        return\n",
    "\n",
    "    root_dir = os.path.abspath(os.getcwd())\n",
    "    filepath = os.path.join(root_dir, subdir, filename)\n",
    "    print(filepath)\n",
    "\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as fp:\n",
    "        # Write text summary\n",
    "        text_summary = \"\\n\\n\".join([t.text.value.strip() for t in message.text_messages])\n",
    "        fp.write(text_summary)\n",
    "\n",
    "        # Write unique URL citations, if present\n",
    "        if message.url_citation_annotations:\n",
    "            fp.write(\"\\n\\n## References\\n\")\n",
    "            seen_urls = set()\n",
    "            for ann in message.url_citation_annotations:\n",
    "                url = ann.url_citation.url\n",
    "                title = ann.url_citation.title or url\n",
    "                if url not in seen_urls:\n",
    "                    fp.write(f\"- [{title}]({url})\\n\")\n",
    "                    seen_urls.add(url)\n",
    "\n",
    "    print(f\"Research summary written to '{filepath}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "110a2060",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agent(thread_id: str, agent_id: str, show_output: bool = True)-> ThreadRun:\n",
    "    print(f\"Start processing the message... this may take a few minutes to finish. Be patient!\")\n",
    "    # Poll the run as long as run status is queued or in progress\n",
    "    run = project_client.agents.runs.create(thread_id=thread.id, agent_id=agent.id)\n",
    "    last_message_id = None\n",
    "    print(f\"Run started with ID: {run.id}, status: {run.status}\")\n",
    "    while run.status in (\"queued\", \"in_progress\"):\n",
    "        time.sleep(1)\n",
    "        run = project_client.agents.runs.get(thread_id=thread.id, run_id=run.id)\n",
    "        \n",
    "        if show_output:\n",
    "            last_message_id = fetch_and_print_new_agent_response(\n",
    "                thread_id=thread.id,\n",
    "                agents_client=project_client.agents,\n",
    "                last_message_id=last_message_id,\n",
    "            )\n",
    "        print(f\"Run status: {run.status}\")\n",
    "\n",
    "    print(f\"Run finished with status: {run.status}, ID: {run.id}\")\n",
    "\n",
    "    if run.status == \"failed\":\n",
    "        print(f\"Run failed: {run.last_error}\")\n",
    "    return run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf82d6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start processing the message... this may take a few minutes to finish. Be patient!\n",
      "Run started with ID: run_LMrwOcPr4kCPuHkxkpdRQD6r, status: RunStatus.QUEUED\n",
      "\n",
      "Agent response:\n",
      "Could you please specify any particular areas or aspects of quantum computing you are most interested in? For example, are you looking for breakthroughs in quantum hardware, algorithms, error correction, applications, or commercial developments? Also, would you like the research focus to be academic papers, industry advancements, or both? This will help me tailor the research to your needs.\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.COMPLETED\n",
      "Run finished with status: RunStatus.COMPLETED, ID: run_LMrwOcPr4kCPuHkxkpdRQD6r\n"
     ]
    }
   ],
   "source": [
    "run = run_agent(thread_id=thread.id, agent_id=agent.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eefb7301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created message, ID: msg_ve4gtZ7SLHty32Pq4hQtvG2e\n"
     ]
    }
   ],
   "source": [
    "message = project_client.agents.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=MessageRole.USER,\n",
    "    content=(\n",
    "        # \"Recent advancements in hardward, algorithms, applications. I prefer a mix of both academic publication and industry news in a structured report. Research and news to the past year.\"\n",
    "        \"Recent advancements in hardward. I prefer only industry news in a structured report. Research and news to the past 3 month.\"\n",
    "    ),\n",
    ")\n",
    "print(f\"Created message, ID: {message.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d53e1e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start processing the message... this may take a few minutes to finish. Be patient!\n",
      "Run started with ID: run_gzHTT4sFfTEgFtsQKu1Q9h6h, status: RunStatus.QUEUED\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.COMPLETED\n",
      "Run finished with status: RunStatus.COMPLETED, ID: run_gzHTT4sFfTEgFtsQKu1Q9h6h\n"
     ]
    }
   ],
   "source": [
    "run = run_agent(thread_id=thread.id, agent_id=agent.id, show_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fba2e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yingdingwang\\Documents\\VCS\\democollections\\ai-foundry-workshop\\01-foundamentals\\data\\research_summary.md\n",
      "Research summary written to 'c:\\Users\\yingdingwang\\Documents\\VCS\\democollections\\ai-foundry-workshop\\01-foundamentals\\data\\research_summary.md'.\n"
     ]
    }
   ],
   "source": [
    "# Fetch the final message from the agent in the thread and create a research summary\n",
    "final_message = project_client.agents.messages.get_last_message_by_role(\n",
    "    thread_id=thread.id, role=MessageRole.AGENT\n",
    ")\n",
    "if final_message:\n",
    "    create_research_summary(final_message, subdir=\"data\", filename=\"research_summary.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "740c16b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_run = project_client.agents.runs.get(thread_id=thread.id, run_id=run.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e4abbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Research Summary Report:\n",
      "Final Report:\n",
      "# Advancements in Quantum Computing Hardware (April–July 2025)\n",
      "\n",
      "Quantum computing hardware has seen significant progress in the past three months. Major industry players have announced new processors, improved performance metrics, and roadmap milestones toward large-scale quantum systems. Below is a structured overview of the latest developments, organized by company and technology, with sources from recent news and official releases.\n",
      "\n",
      "## IBM: Roadmap to Fault Tolerance and New Quantum Systems\n",
      "\n",
      "- **Fault-Tolerant Quantum Roadmap:** In June 2025, IBM unveiled an updated quantum roadmap aiming to build the first large-scale, fault-tolerant quantum computer by 2029【33:4†source】. Codenamed **IBM Quantum Starling**, this future machine is expected to perform **20,000× more operations** than today’s quantum processors【33:4†source】. IBM’s plan introduces intermediate processors – *Loon* (expected 2025), *Kookaburra* (2026), and *Cockatoo* (2027) – which will test modular architectures and error-correction technologies on the path toward the Starling system in 2029【33:4†source】. These steps focus on **quantum low-density parity check (qLDPC)** codes to dramatically reduce the overhead for error correction, addressing a key challenge in scaling up quantum hardware【33:4†source】.\n",
      "\n",
      "- **“Heron” Processor and System Two Deployment:** IBM also reached a major hardware milestone with the deployment of its next-generation **IBM Quantum System Two** in Japan. In June 2025, the first System Two outside the U.S. was unveiled at RIKEN in Kobe, **co-located with the Fugaku supercomputer** – marking the first integration of an IBM quantum computer with an exascale-class classical system【33:5†source】. The machine is powered by IBM’s new **156-qubit** **“Heron”** processor, the company’s highest-performing chip to date【33:5†source】. Heron achieves a two-qubit gate error rate around 3×10^−3 (with best cases at 1×10^−3), which is **10× better fidelity** than the prior 127-qubit Eagle processor, and it runs circuits with a speed (CLOPS) of 250,000 – about **10× faster** than the previous generation【33:5†source】. At 156 qubits with these improved error rates and speeds, Heron is currently **IBM’s most capable quantum processor**, able to execute circuits beyond the brute-force simulation capabilities of classical supercomputers【33:5†source】. This system’s tight integration with Fugaku is enabling experiments in **quantum-centric supercomputing**, where quantum and classical resources work in parallel for tasks like complex chemistry simulations【33:5†source】.\n",
      "\n",
      "## Google: “Willow” Quantum Processor Achieves New Milestones\n",
      "\n",
      "Google’s Quantum AI team announced a breakthrough in hardware with its latest superconducting quantum chip, **code-named “Willow.”** Revealed in a blog update and Nature publication in June 2025, Willow features **105 qubits** and demonstrates **state-of-the-art performance** on multiple fronts:\n",
      "\n",
      "- **Error Correction & “Below-Threshold” Operation:** Willow is the first Google chip to show that adding more qubits *reduces* the error rate exponentially – a regime called “below threshold” in quantum error correction. In contrast to previous generations where scaling up introduced more errors, Willow’s larger qubit arrays produced lower error rates, effectively **halving the error rate with each increase in code size**,. This achievement implies an **exponential error suppression** as the system grows, marking a critical step toward a scalable **logical qubit**. Google’s Hartmut Neven noted that Willow is “the first system below threshold” and *“the most convincing prototype for a scalable logical qubit built to date,”* indicating that truly large, useful quantum computers can be built in the coming years. Willow also showcased one of the first instances of real-time error correction on a superconducting quantum platform.\n",
      "\n",
      "- **Performance Beyond Classical Supercomputers:** In a standard benchmark (random circuit sampling), Willow completed a computation in under **5 minutes** that was estimated to take **10^25 years** (ten septillion years) on Frontier, one of today’s fastest classical supercomputers. This dramatic demonstration of quantum speedup far exceeds Google’s earlier 2019 “quantum supremacy” experiment. The new chip also boasts qubit coherence times around **100 μs**, roughly **5× longer** than Google’s previous  quantum processors. These improvements in coherence and gate fidelity enabled Willow to maintain quantum states and perform deep circuits that outpace classical simulation. The Willow chip was fabricated at Google’s dedicated quantum hardware facility in Santa Barbara, showcasing in-house manufacturing capabilities for cutting-edge quantum designs. *Overall, Google’s Willow announcement signals a major leap in hardware – achieving an error-corrected regime and computational feats that strengthen confidence in eventually attaining practical, large-scale quantum computing,.*\n",
      "\n",
      "## IonQ: Scaling Up Trapped-Ion Systems and Commercial Deployments\n",
      "\n",
      "Trapped-ion quantum computing leader **IonQ** has made several notable announcements this quarter, indicating both technical progress and expanding commercial footprint:\n",
      "\n",
      "- **Quantum Hub Deployment:** In April 2025, IonQ and utility company EPB of Chattanooga announced a **$22 million deal** to establish a new **Quantum Computing and Networking Hub** in Tennessee【33:2†source】,【33:2†source】. As part of this partnership, IonQ will install a state-of-the-art **IonQ Forte Enterprise** system at EPB’s Quantum Center, making **Chattanooga the first U.S. city with a commercially available quantum computing and networking hub**【33:2†source】. The deployed IonQ Forte Enterprise is a **rack-mounted trapped-ion quantum computer** offering high stability and does not require extreme infrastructure, representing a step toward data-center-friendly quantum hardware【33:2†source】. This move not only provides EPB’s customers with access to quantum computing power but also helps develop a quantum-ready workforce through training and collaboration in the region【33:2†source】.\n",
      "\n",
      "- **Acquisitions Accelerating Technology Roadmap:** IonQ is aggressively scaling its hardware capabilities via strategic acquisitions. In June 2025, the company completed the acquisition of **Lightsynq Technologies**, a startup specializing in photonic quantum interconnects and memory【33:8†source】. Integrating Lightsynq’s technology will accelerate IonQ’s roadmap toward **modular, networked quantum systems**, enabling high-bandwidth linking of multiple ion-trap chips【33:8†source】. IonQ’s CEO, Niccolo de Masi, stated that this deal speeds the transition from bulk optical setups to **scalable on-chip photonic links**, bringing the company closer to *“fault-tolerant quantum computers and long-distance quantum networking”*【33:8†source】,【33:8†source】. In the past year, IonQ also announced plans to acquire Oxford Ionics (for chip-integrated ion traps) and QKD firm ID Quantique, assembling key pieces for a distributed, **quantum network** architecture【33:8†source】,【33:8†source】.\n",
      "\n",
      "- **Dramatic Scaling Plan:** Backed by these innovations, IonQ updated its hardware roadmap with an ambitious aim to achieve a **“cryptographically relevant” quantum computer by 2028** – potentially capable of breaking current encryption. By leveraging chip-scale ion trap arrays (from Oxford Ionics) and photonic interconnects (from Lightsynq), IonQ projects a leap from its current **tens of qubits** to about **20,000 physical qubits by 2028**, distributed across two entangled chips. Further, by 2030, they envision reaching **~2,000,000 physical qubits** (across multiple modules) which, under quantum error correction, would correspond to on the order of **$10^4$–$10^5$ logical qubits**,. For context, IonQ estimates ~1,600 error-corrected logical qubits in 2028 could enable basic fault-tolerant algorithms, and tens of thousands of logical qubits in the early 2030s could unlock broad quantum advantage for real-world problems. This roadmap, if achieved, would far surpass IonQ’s previous targets and could make it the first vendor to reach a **cryptography-breaking scale** quantum machine. It also aligns with aggressive industry timelines, as others like IBM and Google similarly target large-scale fault-tolerant systems by the end of the decade,.\n",
      "\n",
      "- **Performance Improvements:** Alongside increasing qubit counts, IonQ has been improving the quality and computational power of its systems. The current flagship **IonQ Forte** and **Forte Enterprise** systems are reported to deliver **36 “algorithmic qubits” (#AQ 36)** of performance【33:8†source】. (*Algorithmic qubit is IonQ’s metric akin to quantum volume, indicating the size of problems the machine can effectively run.*) This is a substantial jump from IonQ’s prior-generation systems (which were in the 20s #AQ), reflecting higher gate fidelities and more complex circuit execution. IonQ’s trapped-ion qubits are intrinsically identical and boast long coherence times, contributing to high **two-qubit gate fidelities** that have been key to reaching the 36 AQ benchmark【33:8†source】. These gains were evidenced by IonQ’s announcement with Ansys that IonQ hardware achieved better performance than classical computing for a certain medical device simulation, highlighting real-world application progress【33:2†source】. With **algorithmic performance improving ~20× over the last few years** and all major cloud platforms offering access to IonQ systems, the company is demonstrating both technical and commercial momentum【33:1†source】.\n",
      "\n",
      "## D-Wave: General Availability of the **Advantage2** Annealing Quantum Computer\n",
      "\n",
      "D-Wave Systems, the leader in quantum annealing technology, has introduced its **most advanced quantum annealer to date**, called **Advantage2**, moving from prototype to full production usage. In May 2025 the company announced the **general availability** of Advantage2, marking D-Wave’s 6th-generation quantum computing system. This machine is a **4,400+ qubit** processor – a significant scale-up – and is now accessible via D-Wave’s Leap cloud service or for on-premises deployment by customers,. D-Wave claims Advantage2’s capacity and speed allow it to solve certain hard optimization problems that are **beyond the reach of classical supercomputers**, underscoring a quantum advantage in its specialized domain. Key hardware improvements in **Advantage2** include:\n",
      "\n",
      "- **Enhanced Qubit Connectivity:** The Advantage2 chip uses a new **Zephyr topology** with **20-way connectivity** between qubits, a leap from the 15-way connectivity of the previous Pegasus topology. This richer inter-qubit coupling means more complex graph problems can be embedded on the quantum chip directly, allowing the solver to handle larger and more intricate optimization tasks natively.\n",
      "\n",
      "- **Higher Energy Scale & Lower Noise:** The new system operates with a **40% higher energy scale** for its qubits and achieves a **75% reduction in noise**, compared to D-Wave’s prior generation. A higher energy scale improves the gap between quantum states, making the annealer more robust against thermal errors, while lower noise leads to more reliable, higher-quality solutions for difficult calculations. These enhancements translate into better outcomes for real-world applications like AI model sampling, scheduling optimization, and material simulations.\n",
      "\n",
      "- **Greater Coherence Time:** **Advantage2 doubles the coherence time** of the quantum annealing process relative to the earlier Advantage system. This twofold increase in coherence (the time qubits can maintain quantum states during the anneal) means the system can perform longer or more complex annealing cycles with reduced risk of decoherence, yielding faster time-to-solution on hard instances. Longer coherence combined with the fast “quantum anneal” feature (rapid annealing schedules) allows Advantage2 to maintain quantum effects during computation and mitigate external disturbances like thermal fluctuations.\n",
      "\n",
      "Together, these technical gains have been validated in benchmarking: D-Wave released a whitepaper showing that at the **4,400-qubit scale**, Advantage2 delivers substantial performance improvements over the previous 5,000-qubit Advantage\\_1 system on a variety of problems【33:3†source】,【33:3†source】. Industry customers have already run over 20 million problems on early Advantage2 prototypes since 2022, and saw up to **10,000× faster performance** on certain tasks versus earlier models【33:3†source】. Now, with the full Advantage2 available at 99.9% uptime through the cloud, D-Wave is also deploying it in strategic locations: one Advantage2 is slated for the Jülich Supercomputing Centre in Europe (to be integrated with the upcoming JUPITER exascale classical system), and another will be installed at Davidson Technologies in Alabama focusing on national defense use cases,. These deployments underscore a trend of **quantum annealers augmenting classical HPC** for specialized workloads. Notably, D-Wave also published peer-reviewed research in *Science* (March 2025) claiming a form of **“quantum computational advantage”** using an Advantage2 prototype on a complex magnetism simulation problem, further stirring debate on quantum supremacy claims in annealing vs. gate-model approaches【33:3†source】. Overall, D-Wave’s hardware progress with Advantage2 reinforces its unique path in the quantum ecosystem, targeting practical optimization and AI applications with an energy-efficient (≈12 kW power) quantum processor that can operate continuously at scale【33:3†source】.\n",
      "\n",
      "## Rigetti: Multi-Chip Superconducting Processor and Fidelity Breakthrough\n",
      "\n",
      "Berkeley-based Rigetti Computing, a smaller industry player specializing in superconducting qubit systems, announced a **significant hardware achievement** in July 2025. The company demonstrated what it calls the **industry’s largest multi-chip quantum processor** to date – a **36-qubit system** composed of four linked 9-qubit chips (“chiplets”) – and achieved a major boost in two-qubit gate fidelity,:\n",
      "\n",
      "- **Modular Multi-Chip Architecture:** Rigetti’s new 36-qubit processor is a proof-of-concept for scaling via a tiled, modular approach. Instead of one large monolithic chip, it uses **four 9-qubit dies** connected together, showcasing Rigetti’s proprietary multi-chip technology for **quantum-classical interconnects**. This design is intended to overcome fabrication limits by stitching smaller high-yield chips into a larger, integrated quantum processor – a crucial capability for expanding superconducting qubit counts beyond the on-chip wiring limits. Rigetti first pioneered multi-chip quantum tech in 2018–2019; now this latest system is the **first of its kind at 36 qubits**, setting the stage for much larger devices.\n",
      "\n",
      "- **Fidelity Milestone:** Alongside the increased qubit count, Rigetti halved its two-qubit gate error rates. The 36-qubit multi-chip system reached a **99.5% median two-qubit gate fidelity**, a **2× improvement** over the company’s previous best (~99.0% median) on its single-chip 84-qubit “Ankaa-3” processor. By reducing the median two-qubit error to 0.5% (from ~1%), Rigetti crossed an important threshold, as 99.5% fidelity approaches the error rates required for basic quantum error correction in superconducting architectures. This fidelity was achieved on controlled-Z (CZ) gates across the multi-chip array, demonstrating that modular coupling did not compromise gate quality. Rigetti attributes the success to refinements in chip design and fabrication (done in-house at its “Fab-1”) and improved control electronics and calibrations.\n",
      "\n",
      "- **Roadmap and Speed Advantages:** Achieving 99.5% fidelity on a modular system also validates Rigetti’s plan to scale to larger processors. The company announced it will **launch the 36-qubit system for public use on August 15, 2025**, and remains on track to deliver a **100+ qubit** chiplet-based quantum computer (likely using a 4-chip stack of 25+ qubits each) *by the end of 2025*, also targeting 99%+ gate fidelities. If realized, that would put Rigetti in reach of triple-digit qubit counts with error rates in the “mid-10^−3” range – competitive with other leading superconducting efforts. Rigetti’s CEO, Subodh Kulkarni, highlighted that their superconducting qubits operate with gate speeds **over 1,000× faster** than some alternative platforms like ion traps. This high speed, combined with modular scaling, could allow Rigetti processors to execute large quantum circuits quickly once high fidelity is maintained at scale. The company’s focus is now on integrating these chiplets seamlessly and improving yield, as it works to deliver on contracts for national labs and scale its cloud offering via partners like AWS and Azure. Investors reacted positively to Rigetti’s July announcement of the 36-qubit breakthrough, with the stock surging on the news, reflecting optimism that the company is progressing toward its goal of an error-corrected 1000-qubit system in the coming years【33:6†source】.\n",
      "\n",
      "## Other Notable Hardware Milestones (Photonic Quantum Computing)\n",
      "\n",
      "While superconducting, ion-trap, and annealing systems dominate the quantum hardware landscape, recent months also saw progress in **photonic quantum computing** – an approach using photons (light) for qubits, which can operate at room temperature. \n",
      "\n",
      "- **ORCA Computing’s Photonic System Deployment:**  UK-based startup **ORCA Computing** delivered its **PT-2 photonic quantum computer** to the U.K.’s National Quantum Computing Centre (NQCC) in June 2025【33:7†source】. This installation is reported as the **first photonic quantum computing system in the UK public sector**, and notably, the PT-2 was up and running within **36 hours** of delivery【33:7†source】 – highlighting the practical ease of deploying room-temperature quantum hardware. ORCA’s PT-2 uses single photons in optical fiber loops as qubits and is designed for **plug-and-play integration with classical high-performance computing (HPC) infrastructure**【33:7†source】. In fact, the NQCC testbed will pair the photonic processor with conventional GPUs to explore hybrid quantum-classical algorithms for machine learning and optimization , . The ORCA PT-2 system focuses on **quantum machine learning** applications (such as quantum-enhanced generative AI) and can interface with NVIDIA’s CUDA quantum libraries, providing a pathway to scale AI workloads with quantum accelerators , . This successful deployment suggests that photonic quantum computers are maturing – offering **modular, rack-mounted quantum units** that can be co-located with standard data center equipment. ORCA’s accomplishment – along with its partnerships (e.g., with Vodafone for telecom network optimization, and with HPC firm ParTec for integrated AI “quantum ready” supercomputers) – underscores that photonic approaches are an emerging part of the quantum hardware ecosystem aiming at **scalable, networked quantum processing** without the cryogenic overhead.\n",
      "\n",
      "- **(Quantum Networking Note):** The period also saw strides in quantum networking hardware, often complementing computing advances. For instance, as noted above, IonQ’s acquisitions (Lightsynq, Qubitekk, ID Quantique) point toward integrating quantum communication capabilities with processors【33:8†source】. Similarly, other firms are developing **modular quantum architectures**: France’s Pasqal (neutral atoms) and Canada’s Xanadu (photonic qubits) have been ramping up R&D, though without specific hardware releases this quarter. These efforts, while not headline announcements in the last three months, form the backdrop of an industry pushing toward **distributed quantum computing** – where multiple quantum nodes work in tandem, connected by photonic links. It’s likely that upcoming quarters will feature more news on hardware that blurs the line between quantum computing and networking.\n",
      "\n",
      "---\n",
      "\n",
      "**Sources:** The above information is compiled from recent press releases, company blogs, and reputable industry news outlets. Key sources include IBM’s newsroom announcements【33:4†source】,【33:5†source】, Google’s official Quantum AI blog and coverage in *Data Center Dynamics*, IonQ’s press releases and analysis from PostQuantum,【33:8†source】, D-Wave’s press release and ZDNet coverage,【33:3†source】, Rigetti’s investor news release,, and photonic quantum computing reports from NQCC and ORCA【33:7†source】. These sources provide detailed verification of the advancements summarized in each section. Each development highlights the rapid pace at which **quantum hardware is evolving in 2025**, bringing the industry closer to practical quantum advantage and eventually fault-tolerant quantum computing.\n",
      "\n",
      "## References\n",
      "- [IBM Sets the Course to Build World's First Large-Scale, Fault-Tolerant ...](https://www.prnewswire.com/news-releases/ibm-sets-the-course-to-build-worlds-first-large-scale-fault-tolerant-quantum-computer-at-new-ibm-quantum-data-center-302476945.html)\n",
      "- [IBM and RIKEN Unveil First IBM Quantum System Two Outside of the U.S.](https://newsroom.ibm.com/2025-06-23-ibm-and-riken-unveil-first-ibm-quantum-system-two-outside-of-the-u-s)\n",
      "- [IonQ Announces $22M Deal with EPB Establishing Chattanooga, Tennessee ...](https://www.businesswire.com/news/home/20250424954681/en/IonQ-Announces-%2422M-Deal-with-EPB-Establishing-Chattanooga-Tennessee-as-the-First-Quantum-Computing-Networking-Hub-in-the-U.S.)\n",
      "- [IonQ Completes Acquisition of Lightsynq, Accelerating Quantum Computing ...](https://www.morningstar.com/news/business-wire/20250603171883/ionq-completes-acquisition-of-lightsynq-accelerating-quantum-computing-and-networking-roadmap)\n",
      "- [IonQ Expands Across APAC Through Strategic Collaboration With ...](https://investors.ionq.com/news/news-details/2025/IonQ-Expands-Across-APAC-Through-Strategic-Collaboration-With-Australian-Company-Emergence-Quantum/default.aspx)\n",
      "- [D-Wave Announces General Availability of Advantage2 Quantum Computer ...](https://www.dwavequantum.com/company/newsroom/press-release/d-wave-announces-general-availability-of-advantage2-quantum-computer-its-most-advanced-and-performant-system/)\n",
      "- [Intel Hits Key Milestone in Quantum Chip Production Research](https://www.intc.com/news-events/press-releases/detail/1581/intel-hits-key-milestone-in-quantum-chip-production-research)\n",
      "- [Google debuts Willow quantum computing chip, claims new breakthroughs](https://www.datacenterdynamics.com/en/news/google-debuts-willow-quantum-computing-chip/)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Load the report\n",
    "report_path = os.path.join(os.getcwd(), \"data\", \"research_summary.md\")\n",
    "if os.path.exists(report_path):\n",
    "    with open(report_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        report_content = file.read()\n",
    "    print(\"Research Summary Report:\")\n",
    "    print(report_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b6cca3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azfdydemo3.12pip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
