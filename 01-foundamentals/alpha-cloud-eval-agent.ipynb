{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03fb5c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment and authentication OK\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# load environment variables from .env file\n",
    "load_dotenv(dotenv_path=\".env\", override=True)\n",
    "\n",
    "from utils.fdyauth import AuthHelper\n",
    "settings = AuthHelper.load_settings()\n",
    "credential = AuthHelper.test_credential()\n",
    "\n",
    "if credential:\n",
    "    print('Environment and authentication OK')\n",
    "else:\n",
    "    print(\"please login first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd68ea3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reusing agent > my-eval-agent-1 (id: asst_yDQOgHuLYD5zhwoebWPPunL7)\n",
      "Created thread, thread ID: thread_PRIrnaeBVfzdnytNQlyn3ml8\n",
      "Created message, message ID: msg_eFcn8wkQBAZpTOCPZb3RZI95\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.COMPLETED\n"
     ]
    }
   ],
   "source": [
    "import os, time\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.projects.models import (\n",
    "    AgentEvaluationRequest,\n",
    "    InputDataset,\n",
    "    EvaluatorIds,\n",
    "    EvaluatorConfiguration,\n",
    "    AgentEvaluationSamplingConfiguration,\n",
    "    AgentEvaluationRedactionConfiguration,\n",
    "    AgentEvaluation,\n",
    ")\n",
    "\n",
    "# not using the settings.agent_name, since this agent name is used by other notebooks\n",
    "AGENT_NAME = \"my-eval-agent-1\"\n",
    "AGENT_INSTRUCTIONS = \"You are helpful agent\"\n",
    "\n",
    "project_client = AIProjectClient(\n",
    "    endpoint=settings.project_endpoint, \n",
    "    credential=credential,\n",
    "#   api_version=settings.project_api_version\n",
    ")\n",
    "\n",
    "# [START evaluations_agent_sample]\n",
    "# project_client.agents.enable_auto_function_calls(tools=toolset, max_retry=4)\n",
    "found_agent = None\n",
    "all_agents_list = project_client.agents.list_agents()\n",
    "for a in all_agents_list:\n",
    "    if a.name == AGENT_NAME:\n",
    "        found_agent = a\n",
    "        break\n",
    "\n",
    "if found_agent:\n",
    "    agent = project_client.agents.update_agent(\n",
    "        agent_id=found_agent.id,\n",
    "        model=settings.model_deployment_name,\n",
    "        instructions=AGENT_INSTRUCTIONS,\n",
    "        # toolset=toolset,\n",
    "    )\n",
    "    # project_client.agents.enable_auto_function_calls(tools=toolset, max_retry=4) \n",
    "    print(f\"reusing agent > {agent.name} (id: {agent.id})\")\n",
    "else:\n",
    "    agent = project_client.agents.create_agent(\n",
    "        model=settings.model_deployment_name,\n",
    "        name=AGENT_NAME,\n",
    "        instructions=AGENT_INSTRUCTIONS,\n",
    "        # toolset=toolset,\n",
    "    )\n",
    "    # print(f\"Created agent '{AGENT_NAME}' with {len(functions._functions)} tools\\nID: {agent.id}\")\n",
    "    print(f\"Created agent '{AGENT_NAME}'\\nID: {agent.id}\")\n",
    "\n",
    "thread = project_client.agents.threads.create()\n",
    "print(f\"Created thread, thread ID: {thread.id}\")\n",
    "\n",
    "message = project_client.agents.messages.create(\n",
    "    thread_id=thread.id, role=\"user\", content=\"Hello, tell me a joke\"\n",
    ")\n",
    "print(f\"Created message, message ID: {message.id}\")\n",
    "\n",
    "run = project_client.agents.runs.create(thread_id=thread.id, agent_id=agent.id)\n",
    "\n",
    "# Poll the run as long as run status is queued or in progress\n",
    "while run.status in [\"queued\", \"in_progress\", \"requires_action\"]:\n",
    "    # Wait for a second\n",
    "    time.sleep(1)\n",
    "    run = project_client.agents.runs.get(thread_id=thread.id, run_id=run.id)\n",
    "    print(f\"Run status: {run.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "786148db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent evaluation created with ID: thread_PRIrnaeBVfzdnytNQlyn3ml8;run_PkJhE6dglbxKCJZAIhh0zstk\n",
      "<class 'azure.ai.projects.models._models.AgentEvaluation'>\n"
     ]
    }
   ],
   "source": [
    "agent_evaluation_request = AgentEvaluationRequest(\n",
    "    run_id=run.id,\n",
    "    thread_id=thread.id,\n",
    "    evaluators={\n",
    "        \"violence\": EvaluatorConfiguration(\n",
    "            id=EvaluatorIds.VIOLENCE,\n",
    "        )\n",
    "    },\n",
    "    sampling_configuration=AgentEvaluationSamplingConfiguration(\n",
    "        name=\"agent-eval-request-sample\",\n",
    "        sampling_percent=100,\n",
    "        max_request_rate=100,\n",
    "    ),\n",
    "    redaction_configuration=AgentEvaluationRedactionConfiguration(\n",
    "        redact_score_properties=False,\n",
    "    ),\n",
    "    app_insights_connection_string=project_client.telemetry.get_connection_string(),\n",
    ")\n",
    "\n",
    "agent_evaluation_response: AgentEvaluation = project_client.evaluations.create_agent_evaluation(\n",
    "    evaluation=agent_evaluation_request,\n",
    "    headers={\n",
    "        \"model-endpoint\": settings.azure_openai_endpoint,\n",
    "        \"api-key\": settings.azure_openai_api_key,\n",
    "    },\n",
    ")\n",
    "\n",
    "print(f\"agent evaluation created with ID: {agent_evaluation_response.id}\")\n",
    "print(type(agent_evaluation_response))\n",
    "\n",
    "\n",
    "# print(\"List evaluations\")\n",
    "# for evaluation in project_client.evaluations.list():\n",
    "#     print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d4399a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Thread ID: thread_PRIrnaeBVfzdnytNQlyn3ml8\n",
      "Eval Run ID: run_PkJhE6dglbxKCJZAIhh0zstk\n"
     ]
    }
   ],
   "source": [
    "# split the agent_evaluation_response.id by \";\"\n",
    "# the first part assign to eval_thread_id\n",
    "# the second part assign to eval_run_id\n",
    "eval_thread_id, eval_run_id = agent_evaluation_response.id.split(\";\")\n",
    "print(f\"Eval Thread ID: {eval_thread_id}\")\n",
    "print(f\"Eval Run ID: {eval_run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "13f51455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'run_PkJhE6dglbxKCJZAIhh0zstk', 'object': 'thread.run', 'created_at': 1751892638, 'assistant_id': 'asst_yDQOgHuLYD5zhwoebWPPunL7', 'thread_id': 'thread_PRIrnaeBVfzdnytNQlyn3ml8', 'status': 'completed', 'started_at': 1751892638, 'expires_at': None, 'cancelled_at': None, 'failed_at': None, 'completed_at': 1751892639, 'required_action': None, 'last_error': None, 'model': 'gpt-4.1-mini', 'instructions': 'You are helpful agent', 'tools': [], 'tool_resources': {}, 'metadata': {}, 'temperature': 1.0, 'top_p': 1.0, 'max_completion_tokens': None, 'max_prompt_tokens': None, 'truncation_strategy': {'type': 'auto', 'last_messages': None}, 'incomplete_details': None, 'usage': {'prompt_tokens': 29, 'completion_tokens': 22, 'total_tokens': 51, 'prompt_token_details': {'cached_tokens': 0}}, 'response_format': 'auto', 'tool_choice': 'auto', 'parallel_tool_calls': True}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_client.agents.runs.get(thread_id=eval_thread_id, run_id=eval_run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a616ba7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'thread_PRIrnaeBVfzdnytNQlyn3ml8', 'object': 'thread', 'created_at': 1751892636, 'metadata': {}, 'tool_resources': {'code_interpreter': {'file_ids': []}, 'azure_ai_search': {'indexes': []}}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_client.agents.threads.get(thread_id=eval_thread_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azfdydemo3.12pip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
